{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predict tracrRNAs</h1>\n",
    "<ol>\n",
    "    <li><a id=\"libraries\">Load Libraries</a></li>\n",
    "    <li><a href=\"#blast\">BLAST the consensus repeat of a CRISPR array</a></li>\n",
    "    <li><a href=\"#round0Prep\">Round 0</a></li>\n",
    "    <li><a href=\"#round0Results\">Round 0 - Results</a></li>\n",
    "    <li><a href=\"#round1Prep\">Round 1</a></li>\n",
    "    <li><a href=\"#round1Results\">Round 1 - Results</a></li>\n",
    "    <li><a href=\"#round2Prep\">Round 2</a></li>\n",
    "    <li><a href=\"#round2Results\">Round 2 - Results</a></li>\n",
    "    <li><a href=\"#combinedResults\">Combined Results</a></li>\n",
    "    <li><a href=\"#everything\">Extracting Results</a></li>   \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded libraries\n",
      "Number of Cas9s: 2,147\n",
      "Loading Operons\n",
      "Ready to rock and roll!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# import tempfile\n",
    "from sys import path as spath\n",
    "spath.append(\"scripts/\")\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio.SeqIO import index as fasta_index, parse, write\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from CRISPRtools import * #MakeFasta, PilerCRReader, MinCEDReader\n",
    "from easyFunctions import BLAST_short, Coordinate, dump\n",
    "from InfernalResults import *\n",
    "from HMMParser import *\n",
    "from os import chdir, path, stat, system\n",
    "from pandas import Series\n",
    "from pickle import load\n",
    "#from Rho import *\n",
    "# from RhoTermPredict import RhoTermPredict\n",
    "from easyFunctions import dump\n",
    "\n",
    "################################         Data          ################################\n",
    "print(\"Loaded libraries\")\n",
    "chdir(\"/mnt/research/germs/shane/transActRNA/data\")\n",
    "gene = \"Cas9\"\n",
    "casRelatedProteins = fasta_index(\"proteins/%s-Like-clustered.faa\" % (gene),\"fasta\")\n",
    "print(\"Number of %ss: %s\" % (gene,comma(len(casRelatedProteins))))\n",
    "breakPoints = set(range(100,len(casRelatedProteins),100))\n",
    "print(\"Loading Operons\")\n",
    "casOperons = load(open(\"pickles/%s_Operons.p\" % gene,\"rb\"))\n",
    "print(\"Ready to rock and roll!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"annotate\">Annotate</a></h2>\n",
    "\n",
    "[Ref](#ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "operon.annotate = MethodType(annotate,operon)\n",
    "# infernalResults = ProcessInfernal(0,gene)\n",
    "operon.annotate(protID,infernalResults.seqTracrs[protID])\n",
    "\n",
    "counter = 0\n",
    "for protID in infernalResults.seqTracrs:\n",
    "    operon = casOperons.operons[casOperons.seqMap[protID]]\n",
    "    crispr = operon.getCRISPR(protID)\n",
    "    crispr.repeatSeqs(protID,open(operon.getRepeatPath(protID),'w'))\n",
    "    blastResults = parseBLAST(BLAST_short(operon.getRepeatPath(protID), operon.getFastaPointer(protID), \"blastout/conRepeats/%s.xml\" % (protID)))\n",
    "    if len(blastResults) == 0: continue\n",
    "    crispr.clusterBLASTResults(blastResults)\n",
    "    if len(crispr.antiRepeats) == 0: print(\"No anti's in %s?\"%(protID))\n",
    "    crispr.terminators = []\n",
    "    crispr.getAntiRepeatCandidates(open(\"tmp/possibleTracrs.fasta\",\"w\"), operon.getSeq())\n",
    "    res = system(\"~/bin/Arnold/erpin ~/bin/Arnold/rho-indep.epn tmp/possibleTracrs.fasta -1,4 -add 1 4 2 -pcw 3.0 -cutoff 100% >tmp/rhoInd.out\")\n",
    "    erpOut = ErpinOut()\n",
    "    crispr.getTracrRNA_Candidates(erpOut,open(\"test.txt\",'w'))\n",
    "    operon.annotate = MethodType(annotate,operon)\n",
    "    retVal = operon.annotate(protID,infernalResults.seqTracrs[protID]) \n",
    "    counter += int(retVal is not None)\n",
    "counter\n",
    "s1=\"ggaagtctatcagggagttaggtaactgattcccagc\".upper()\n",
    "s2=\"aacgcgagtgtagcttaatggtaaagcctctgccttccaagcagatgacgcgggttcgattcccgtcactcgc\".upper()[:len(s1)+5]\n",
    "print(calcPercIdent(s1,s2))\n",
    "alignSequence(s2,s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"blast\">BLAST</a> for the consensus repeat, look for termination signals from results, annotate each system </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to create blastDB assemblies/pseudoChromos/AAAHNU010000003.1_ORF209.fasta\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9b01fe7a300c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Step 3. Blast the consensus repeats against the Cas-like protein-containing chromosome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mblastResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparseBLAST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBLAST_short\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetRepeatPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFastaPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"blastout/conRepeats/%s.xml\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprotID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblastResults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnoPredictedTracr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprotID\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'No BLAST results'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/easyFunctions.py\u001b[0m in \u001b[0;36mparseBLAST\u001b[0;34m(results, coordsOnly)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparseBLAST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoordsOnly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#TODO:Currently coords only is the only supported parsing method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0malignment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malignments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhsp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malignment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhsps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "noPredictedTracr = {} # {ID:Reason it didn't have a tracr}\n",
    "totalSols, erpSols, breakCount, hadToGetSeq = 0, 0, 0, 0\n",
    "possibleSol = open(\"sequences/temp%s_predictedTracrRNAs.fasta\" % (gene),\"w\")\n",
    "for i, protID in enumerate(casRelatedProteins): #     protID = 'NFJO01000020_ORF977'\n",
    "    # Step 1. Get the CRISPR operon = casOperons[protID]\n",
    "    operon = casOperons.operons[casOperons.seqMap[protID]]\n",
    "    crispr = operon.getCRISPR(protID)\n",
    "    #crispr.repeatSeqs = MethodType(repeatSeqs,crispr)\n",
    "    \n",
    "    # Step 2. Write all consensus repeats to a file\n",
    "    crispr.repeatSeqs(protID,open(operon.getRepeatPath(protID),'w'))\n",
    "\n",
    "    # Step 3. Blast the consensus repeats against the Cas-like protein-containing chromosome\n",
    "    blastResults = parseBLAST(BLAST_short(operon.getRepeatPath(protID), operon.getFastaPointer(protID), \"blastout/conRepeats/%s.xml\" % (protID)))\n",
    "    if len(blastResults) == 0: \n",
    "        noPredictedTracr[protID] = 'No BLAST results'\n",
    "        continue\n",
    "    \n",
    "    #Step 4. Narrow the blast results down by removing crRNAs\n",
    "    crispr.clusterBLASTResults(blastResults)\n",
    "     \n",
    "    # Step 5. Get the approriate flanking sequence for each anti-repeat candidate\n",
    "    if len(crispr.antiRepeats) == 0:\n",
    "        noPredictedTracr[protID] = 'No Anti-repeats'\n",
    "        continue\n",
    "    if operon.seq is None: hadToGetSeq += 1; operon.seq = fasta_index(operon.getFastaPointer(protID),'fasta')[protID]\n",
    "\n",
    "    crispr.getAntiRepeatCandidates(open(\"tmp/possibleTracrs.fasta\",\"w\"), operon.getSeq())\n",
    "    \n",
    "    # Step 6. Look for termination signals\n",
    "    res = system(\"~/bin/Arnold/erpin ~/bin/Arnold/rho-indep.epn tmp/possibleTracrs.fasta -1,4 -add 1 4 2 -pcw 3.0 -cutoff 100% >tmp/rhoInd.out\")\n",
    "    if res != 0:\n",
    "        noPredictedTracr[protID] = 'Erpin Failed %i' % (res)\n",
    "        continue\n",
    "    \n",
    "    # Step 7. Read the termination signals\n",
    "    erpOut = ErpinOut()\n",
    "    erpSols += len(erpOut.terminators)\n",
    "\n",
    "    # Step 8. Get tracrRNA candidates with rho-ind signals\n",
    "    numNewTracrs = crispr.getTracrRNA_Candidates(erpOut,possibleSol)\n",
    "    if numNewTracrs == 0: noPredictedTracr[protID] = 'No terminators'\n",
    "    \n",
    "    # Keep track of how many solutions have been found so far and print\n",
    "    totalSols += numNewTracrs\n",
    "    if i in breakPoints: print(i,end=' ')\n",
    "    if i >50: break\n",
    "\n",
    "possibleSol.close()\n",
    "#dump(casOperons, \"pickles/%s_Operons.p\" % gene)\n",
    "#dump(noPredictedTracr, \"pickles/%sWithNoPredictedTracr.p\" % (gene))\n",
    "print(\"\\nErpin Solutions:\", erpSols)\n",
    "print(\"Found %i possible tracr solutions from %i assmeblies\" % (totalSols,len(casRelatedProteins)-len(noPredictedTracr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"round0Prep\">Round 0 - Predictions From Scratch</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $gene\n",
    "cd-hit-est -i sequences/$1_predictedTracrRNAs.fasta -o sequences/$1_predictedTracrRNAs.grouped.fasta -M 0 -d 0 -c .85 -T 0 -s .90 -sc 1 >logs/$1_tracrClusterLog.log\n",
    "tail -n 8 logs/$1_tracrClusterLog.log > logs/clusterInfo\n",
    "head -n 1 logs/clusterInfo; rm logs/clusterInfo\n",
    "mv sequences/$1_predictedTracrRNAs.grouped.fasta.clstr clusters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 399 clusters\n"
     ]
    }
   ],
   "source": [
    "tRound, nClusters = 4, 0\n",
    "clusteredResults = processClusterFile(\"clusters/All_%s_Predicted_TracrRNAs.grouped.fasta.clstr\" % (gene))\n",
    "seqs = fasta_index(\"sequences/All_%s_Predicted_TracrRNAs.fasta\" % (gene),\"fasta\")\n",
    "for cluster,clusterSeqIDs in clusteredResults.items():\n",
    "    if len(clusterSeqIDs.members) == 1: continue \n",
    "    hasMultipleAsms = False\n",
    "    baseID = list(clusterSeqIDs.members.keys())[0]\n",
    "    baseID = baseID[:baseID.rfind(\"_\")] #remove the solution #\n",
    "    baseID = baseID[:baseID.rfind(\"_\")] #remove the orf ID\n",
    "    for seqID in clusterSeqIDs.members: hasMultipleAsms = (hasMultipleAsms or baseID not in seqID)\n",
    "    if not hasMultipleAsms or len(clusterSeqIDs.members)<=1: continue\n",
    "    with open(\"conseqs%i/%s.fasta\" % (tRound,cluster.replace(\" \",\"_\")),\"w\") as fh:\n",
    "        nClusters += 1\n",
    "        for tracrSeqID in clusterSeqIDs.members: write(seqs[tracrSeqID],fh,\"fasta\")\n",
    "print(\"There are %i clusters\" %(nClusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bash LaunchStructureSearch.sh 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"round0Results\">Round 0 - Results</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 0\n",
    "infernalResults = ProcessInfernal(tRound,gene) # Results from the last structural search\n",
    "generateColors(infernalResults,casRelatedProteins,tRound,gene)\n",
    "clusters = infernalResults.structMapping.keys()\n",
    "seqIDs = infernalResults.seqTracrs.keys()\n",
    "dataMap = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 3\n",
    "infernalResults = ProcessInfernal(tRound,gene) # Results from the last structural search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyFunctions import dump\n",
    "clusterCounter,treeMap,revMap, missingIDs = {}, {}, {}, set()\n",
    "for struct,ids in infernalResults.structMapping.items(): clusterCounter[struct] = len(ids)\n",
    "for protID in casRelatedProteins:\n",
    "    if protID not in infernalResults.seqTracrs: missingIDs.add(protID); continue\n",
    "    biggestCluster =  findBiggestCluster(infernalResults.seqTracrs[protID].keys(),clusterCounter)\n",
    "    treeMap[protID] = biggestCluster\n",
    "    try: revMap[biggestCluster].add(protID)\n",
    "    except: revMap[biggestCluster] = set([protID])\n",
    "treeColors,colors = {},{}\n",
    "for cluster, protIDs in revMap.items():\n",
    "    colors[cluster]=color()\n",
    "    for protID in protIDs: treeColors[protID] = colors[cluster]\n",
    "dump(treeColors,\"pickles/%s_StructureResultsTreeColors_Round%i.p\" % (gene,tRound))\n",
    "dump(colors,    \"pickles/%s_StructureResultsColors_Round%i.p\"     % (gene,tRound))\n",
    "print(\"In round %i, %i assmebly had a predicted tracr (%.1f %%) with %i tracrRNA Structures\" % (tRound,len(treeMap),len(treeMap)/float(len(casRelatedProteins))*100,len(revMap)))\n",
    "print(\"\\t%i still remaining\" % (len(missingIDs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"round1Prep\">Round 1 - Get the tracr results and re-run structural results from the hits</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 1\n",
    "# casOperons = load(open(\"pickles/casOperonDataStructureW%s.p\" % gene,\"rb\"))\n",
    "clusterCMD = \"\"\"\n",
    "cd-hit-est -i sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta -o sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta -M 0 -d 0 -c .85 -s .9 -sc 1\n",
    "\"\"\"\n",
    "for clusterID, protIDs in revMap.items():\n",
    "    with open('sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta' % (gene,tRound,clusterID),'w') as clusterFile:\n",
    "        for protID in protIDs:\n",
    "            tracr = infernalResults.seqTracrs[protID][clusterID]\n",
    "            chrAsmName = \"assemblies/pseudoChromos/%s.fasta\" % (protID)\n",
    "            seq = fasta_index(chrAsmName,\"fasta\")[protID]\n",
    "            newSeq = seq.seq[tracr.location.start:tracr.location.end].upper()\n",
    "            seq.seq = newSeq\n",
    "            seq.description = \"\"\n",
    "            write(seq,clusterFile,\"fasta\")\n",
    "    seqs = fasta_index(\"sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta\" % (gene,tRound,clusterID),\"fasta\")\n",
    "    if len(seqs) == 1 :continue\n",
    "    os.system(clusterCMD % (gene,tRound,clusterID,gene,tRound,clusterID))\n",
    "    print(\"There are %i TRACRs in %s\" % (len(seqs),clusterID))\n",
    "    clusteredResults = processClusterFile(\"sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta.clstr\" % (gene,tRound,clusterID))\n",
    "    for cluster,clusterSeqIDs in clusteredResults.items():\n",
    "        if len(clusterSeqIDs.members) == 1: continue \n",
    "        if len(clusterSeqIDs.members) == 2: \n",
    "            s1, s2 = list(clusterSeqIDs.members.keys())\n",
    "            if clusterSeqIDs.members[s1] == 100.0 or clusterSeqIDs.members[s2] == 100.0: continue\n",
    "        with open(\"conseqs%i/%s_%s.fasta\" % (tRound,clusterID,cluster.replace(\"Cluster \",\"\")),\"w\") as fh:\n",
    "            for tracrSeqID in clusterSeqIDs.members: write(seqs[tracrSeqID],fh,\"fasta\")\n",
    "    os.system(\"rm sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta\" % (gene,tRound,clusterID,gene,tRound,clusterID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export fastaDir=conseqs2\n",
    "for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 26 * 20 is the max CPU limit per user\n",
    "do\n",
    "    #Initial Numbers\n",
    "    squeue -u dooleys1 -o \"%.8i %.9P %.18j %.8u %.2t %.10M %.6D %R\" | grep Priority |wc -l > queuedJobs\n",
    "    read njobs < queuedJobs\n",
    "    ls $fastaDir/*.fasta 2>/dev/null | wc -l >remaining\n",
    "    read whatsLeft < remaining\n",
    "\n",
    "    #Check that something isn't still queued and that there is more to run\n",
    "    while [ $njobs -gt 0 ] && [ $whatsLeft -gt 0 ]; do\n",
    "        sleep 10\n",
    "        squeue -u dooleys1 -o \"%.8i %.9P %.18j %.8u %.2t %.10M %.6D %R\" | grep Priority |wc -l > queuedJobs\n",
    "        read njobs < queuedJobs\n",
    "        ls $fastaDir/*.fasta 2>/dev/null | wc -l >remaining\n",
    "        read whatsLeft < remaining\n",
    "       # echo \"2There are $whatsLeft fasta files remaining\"\n",
    "    done\n",
    "\n",
    "    #Run the new job\n",
    "    sbatch --job-name=\"StructureSearch$i\" ../scripts/hpc/StructureSearch.sb\n",
    "    sleep 10\n",
    "\n",
    "    #Check how many jobs are running and that there is still work to be done\n",
    "    squeue -u dooleys1 -o \"%.8i %.9P %.18j %.8u %.2t %.10M %.6D %R\" | wc -l > totalJobs\n",
    "    read tjobs < totalJobs\n",
    "    ls $fastaDir/*.fasta 2>/dev/null |wc -l >remaining\n",
    "    read whatsLeft < remaining\n",
    "    if [ $tjobs -ge 26 -o $whatsLeft -eq 0 ]; then\n",
    "        break\n",
    "    fi\n",
    "done\n",
    "rm queuedJobs totalJobs remaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"round1Results\">Round 1 - Results</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 1\n",
    "infernalResults0 = ProcessInfernal(0,gene)\n",
    "infernalResults1 = ProcessInfernal(tRound,gene)\n",
    "hasResultInBoth = set(infernalResults0.seqTracrs.keys()).intersection(infernalResults1.seqTracrs.keys())\n",
    "len(hasResultInBoth)\n",
    "\n",
    "infernalResults = infernalResults1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 2 Iterative Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 2\n",
    "from easyFunctions import dump\n",
    "clusterCounter,treeMap,revMap, missingIDs = {}, {}, {}, set()\n",
    "for struct,ids in infernalResults.structMapping.items(): clusterCounter[struct] = len(ids)\n",
    "for protID in casRelatedProteins:\n",
    "    if protID not in infernalResults.seqTracrs: missingIDs.add(protID); continue\n",
    "    biggestCluster =  findBiggestCluster(infernalResults.seqTracrs[protID].keys(),clusterCounter)\n",
    "    treeMap[protID] = biggestCluster\n",
    "    try: revMap[biggestCluster].add(protID)\n",
    "    except: revMap[biggestCluster] = set([protID])\n",
    "        \n",
    "\n",
    "# casOperons = load(open(\"pickles/casOperonDataStructureW%s.p\" % gene,\"rb\"))\n",
    "clusterCMD = \"\"\"\n",
    "cd-hit-est -i sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta -o sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta -M 0 -d 0 -c .85 -s .9 -sc 1\n",
    "\"\"\"\n",
    "for clusterID, protIDs in revMap.items():\n",
    "    with open('sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta' % (gene,tRound,clusterID),'w') as clusterFile:\n",
    "        for protID in protIDs:\n",
    "            tracr = infernalResults.seqTracrs[protID][clusterID]\n",
    "            chrAsmName = \"assemblies/pseudoChromos/%s.fasta\" % (protID)\n",
    "            seq = fasta_index(chrAsmName,\"fasta\")[protID]\n",
    "            newSeq = seq.seq[tracr.location.start:tracr.location.end].upper()\n",
    "            seq.seq = newSeq\n",
    "            seq.description = \"\"\n",
    "            write(seq,clusterFile,\"fasta\")\n",
    "    seqs = fasta_index(\"sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta\" % (gene,tRound,clusterID),\"fasta\")\n",
    "    if len(seqs) == 1 :continue\n",
    "    os.system(clusterCMD % (gene,tRound,clusterID,gene,tRound,clusterID))\n",
    "    print(\"There are %i TRACRs in %s\" % (len(seqs),clusterID))\n",
    "    clusteredResults = processClusterFile(\"sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta.clstr\" % (gene,tRound,clusterID))\n",
    "    for cluster,clusterSeqIDs in clusteredResults.items():\n",
    "        if len(clusterSeqIDs.members) == 1: continue \n",
    "        if len(clusterSeqIDs.members) == 2: \n",
    "            s1, s2 = list(clusterSeqIDs.members.keys())\n",
    "            if clusterSeqIDs.members[s1] == 100.0 or clusterSeqIDs.members[s2] == 100.0: continue\n",
    "        with open(\"conseqs%i/%s_%s.fasta\" % (tRound,clusterID,cluster.replace(\"Cluster \",\"\")),\"w\") as fh:\n",
    "            for tracrSeqID in clusterSeqIDs.members: write(seqs[tracrSeqID],fh,\"fasta\")\n",
    "    os.system(\"rm sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta\" % (gene,tRound,clusterID,gene,tRound,clusterID))\n",
    "# treeColors,colors = {},{}\n",
    "# for cluster, protIDs in revMap.items():\n",
    "#     colors[cluster]=color()\n",
    "#     for protID in protIDs: treeColors[protID] = colors[cluster]\n",
    "# dump(treeColors,\"pickles/%s_StructureResultsTreeColors_Round%i.p\" % (gene,tRound))\n",
    "# dump(colors,    \"pickles/%s_StructureResultsColors_Round%i.p\"     % (gene,tRound))\n",
    "# print(\"In round %i, %i assmebly had a predicted tracr (%.1f %%) with %i tracrRNA Structures\" % (tRound,len(treeMap),len(treeMap)/float(len(casRelatedAssemblies))*100,len(revMap)))\n",
    "# print(\"\\t%i still remaining\" % (len(missingIDs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBiggestCluster(clusters, clusterMap): return Counter(dict((k, clusterMap[k]) for k in (clusters))).most_common(1)[0][0] \n",
    "def getNonOverlapping(topTracr,allTracrs):\n",
    "    tracrCoords = set(range(topTracr.location.start,topTracr.location.end+1))\n",
    "    keepers = set([topTracr])\n",
    "    for tracr in allTracrs:\n",
    "        if tracr.location.start not in tracrCoords and tracr.location.end not in tracrCoords:\n",
    "            tracrCoords = tracrCoords.union(set(range(tracr.location.start,tracr.location.end+1)))\n",
    "            keepers.add(tracr)\n",
    "    \n",
    "#     tracrCoords = list(tracrCoords)\n",
    "#     tracrCoords.sort()\n",
    "#     prev  = tracrCoords[0]\n",
    "#     print(prev, end=\" \")\n",
    "#     for val in tracrCoords[1:]:\n",
    "#         if val-prev != 1:\n",
    "#             print(val)\n",
    "#         prev=val\n",
    "    for tr in keepers:\n",
    "        print(tr)\n",
    "        \n",
    "    return keepers\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineTracrs(inf1,inf2,top1,top2,protID,operon,seqs,clusters):\n",
    "    topClus1 = findBiggestCluster(inf1.seqTracrs[protID].keys(),top1)\n",
    "    topTracr = inf1.seqTracrs[protID][topClus1]\n",
    "    antiCoords = set()\n",
    "    \n",
    "    tracrs = set()\n",
    "    for coord in operon.crispr.antiRepeats: antiCoords = antiCoords.union(set(range(coord.start,coor.end+1)))\n",
    "    notMatching        \n",
    "    \n",
    "    \n",
    "    \n",
    "    topClus2 = findBiggestCluster(inf2.seqTracrs[protID].keys(),top2)\n",
    "    print(protID,inf1.seqTracrs[protID][topClus1],inf2.seqTracrs[protID][topClus2])\n",
    "    print(\"\\tAnti-Repeats:\")\n",
    "    for coord in operon.crispr.antiRepeats:\n",
    "        print(\"\\t\\t\",coord)\n",
    "    \n",
    "\n",
    "    tracrs1 = getNonOverlapping(inf1.seqTracrs[protID][topClus1],inf1.seqTracrs[protID].values())\n",
    "    tracrs2 = getNonOverlapping(inf2.seqTracrs[protID][topClus2],inf2.seqTracrs[protID].values())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(tracrLocs[-1])\n",
    "#     print(\"%s T1 %i\" % (protID,len(tracrs1)))\n",
    "#     for cluster, tracr in tracrs1.items(): \n",
    "# #         for t2 in tracrLocs:\n",
    "            \n",
    "#         print('\\t',tracr)\n",
    "#         tracrLocs.add(tracr)\n",
    "#     print(\"%s T2 %i\" % (protID,len(tracrs2)))\n",
    "#     for cluster, tracr in tracrs2.items(): \n",
    "#         print('\\t',tracr)\n",
    "#         tracrLocs.add(tracr)\n",
    "#     print(len(tracrLocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf0Counter = Counter()\n",
    "for clustID, ids in infernalResults0.structMapping.items(): inf0Counter[clustID] = len(ids)\n",
    "inf1Counter = Counter()\n",
    "for clustID, ids in infernalResults1.structMapping.items(): inf1Counter[clustID] = len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operon.crispr.antiRepeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedResultsBySeq,combinedResultsByLocation = {},{} \n",
    "for i, protID in enumerate(hasResultInBoth):\n",
    "    operon = casOperons[protID]\n",
    "    tracrLocs = combineTracrs(infernalResults0, infernalResults1, inf0Counter, inf1Counter, protID,operon,combinedResultsBySeq,combinedResultsByLocation)\n",
    "    if i == 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"round2Prep\">Round 2 - Take the results from the first 2 runs, combine the unique runs and run again</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterTracrs(tracrs1,tracrs2,consRepeat,asmSeq):\n",
    "    #TODO: check the output of infernal and make sure we aren't stomping on multiple tracrs in same cluster out\n",
    "    #What does the union of tracrs look like?\n",
    "    allTracrs = set()\n",
    "    for cluster, tracr in tracrs1.items():\n",
    "        try:\n",
    "            tracrSeq = tracr.seq(asmSeq)\n",
    "            tracrIdent = duplexPercIdent(tracrSeq,consRepeat)\n",
    "            if tracrIdent >= 35.0: allTracrs.add(tracr)\n",
    "        except: print(consRepeat,asmSeq)\n",
    "    for cluster,tracr in tracrs2.items():\n",
    "        tracrSeq = tracr.seq(asmSeq)\n",
    "        tracrIdent = duplexPercIdent(tracrSeq,consRepeat)\n",
    "        if tracrIdent >= 35.0: allTracrs.add(tracr)\n",
    "    return allTracrs\n",
    "def duplexPercIdent(tracrRNA,crRNA):\n",
    "    crLen = len(crRNA)\n",
    "    if len(tracrRNA) <= crLen: return 0.0\n",
    "    fmatches,rmatches = 0,0\n",
    "    for i in range(crLen): \n",
    "        fmatches += int(tracrRNA[i]==crRNA[i])\n",
    "        rmatches += int(tracrRNA[-(i+1)]==crRNA[-(i+1)])\n",
    "    revComp = RC(crRNA)\n",
    "    rfmatches,rrmatches = 0,0\n",
    "    for i in range(crLen): \n",
    "        rfmatches += int(tracrRNA[i]==revComp[i])\n",
    "        rrmatches += int(tracrRNA[-(i+1)]==revComp[-(i+1)])\n",
    "    crLen = float(crLen)\n",
    "    return max(fmatches/crLen, rmatches/crLen, rfmatches/crLen, rrmatches/crLen)*100\n",
    "\n",
    "tRound = 2\n",
    "possibleSol = open(\"sequences/%s_predictedTracrRNAs_Round%i.fasta\" % (gene,tRound),\"w\")\n",
    "# casOperons = load(open(\"pickles/casOperonDataStructureW%s.p\" % gene,\"rb\"))\n",
    "counter = 0\n",
    "tracrCount = 0\n",
    "for protID in casRelatedAssemblies:\n",
    "    if protID in infernalResults0.seqTracrs and protID in infernalResults1.seqTracrs:\n",
    "        counter+=1\n",
    "        operon = casOperons[protID]\n",
    "        if operon.seq is None:\n",
    "            chrAsmName = \"assemblies/pseudoChromos/%s.fasta\" % (protID)\n",
    "            operon.seq = fasta_index(chrAsmName,'fasta')[protID]\n",
    "        validTracrs = filterTracrs(infernalResults0.seqTracrs[protID],infernalResults1.seqTracrs[protID],list(operon.crispr.consensusRepeats)[0],operon.seq)\n",
    "        for tracr in validTracrs:\n",
    "            tracrCount += 1\n",
    "            possibleSol.write((\">Seq_%i\\n%s\\n\")% (tracrCount,tracr.seq(operon.seq.seq)))\n",
    "possibleSol.close()  \n",
    "tracrCount,counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 2\n",
    "tracrCount = 0\n",
    "possibleSol = open(\"sequences/%s_predictedTracrRNAs_Round%i.fasta\" % (gene,tRound),\"w\")\n",
    "for protID in casRelatedAssemblies:\n",
    "    if protID in infernalResults0.seqTracrs and protID in infernalResults1.seqTracrs:\n",
    "        operon = casOperons[protID]\n",
    "        if operon.seq is None:\n",
    "            chrAsmName = \"assemblies/pseudoChromos/%s.fasta\" % (protID)\n",
    "            operon.seq = fasta_index(chrAsmName,'fasta')[protID]\n",
    "        for id, tracr in infernalResults0.seqTracrs[protID].items():\n",
    "            tracrCount += 1\n",
    "            possibleSol.write((\">Seq_%i\\n%s\\n\")% (tracrCount,tracr.seq(str(operon.seq.seq))))\n",
    "        for id, tracr in infernalResults1.seqTracrs[protID].items():\n",
    "            tracrCount += 1\n",
    "            possibleSol.write((\">Seq_%i\\n%s\\n\")% (tracrCount,tracr.seq(str(operon.seq.seq))))\n",
    "possibleSol.close()  \n",
    "tracrCount,counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $gene $tRound\n",
    "cd-hit-est -i sequences/$1_predictedTracrRNAs_Round$2.fasta -o sequences/$1_predictedTracrRNAs_Round$2.grouped.fasta -M 0 -d 0 -c .85 -s .9 -sc 1 >logs/$1_tracrClusterLog.log\n",
    "tail -n 8 logs/$1_tracrClusterLog.log > logs/clusterInfo\n",
    "head -n 1 logs/clusterInfo; rm logs/clusterInfo\n",
    "mv sequences/$1_predictedTracrRNAs_Round$2.grouped.fasta.clstr clusters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 2\n",
    "numClusts = 0 \n",
    "clusteredResults = processClusterFile(\"clusters/%s_predictedTracrRNAs_Round%i.grouped.fasta.clstr\" % (gene,tRound))\n",
    "seqs = fasta_index(\"sequences/%s_predictedTracrRNAs_Round%i.fasta\" % (gene,tRound),\"fasta\")\n",
    "for cluster,clusterSeqIDs in clusteredResults.items():\n",
    "    if len(clusterSeqIDs.members) == 1: continue \n",
    "#     if len(clusterSeqIDs.members) == 2:\n",
    "    with open(\"conseqs%i/%s.fasta\" % (tRound,cluster.replace(\" \",\"_\")),\"w\") as fh:\n",
    "        numClusts+=1\n",
    "        for tracrSeqID in clusterSeqIDs.members: write(seqs[tracrSeqID],fh,\"fasta\")\n",
    "numClusts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bash LaunchStructureSearch.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"round2Results\">Round 2 - Results</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 2\n",
    "infernalResults = ProcessInfernal(tRound,gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"combinedResults\">Results from all 3 rounds</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "combinedResults = set()\n",
    "infernalResults = [0,1,2,3,4]\n",
    "# allResults =  open(\"sequences/%s_combinedStructuralResults.fasta\" % (gene),\"w\")\n",
    "for i in range(0,3):\n",
    "    beforeNum = len(combinedResults)\n",
    "    infernalResults[i] = ProcessInfernal(i,gene)\n",
    "    combinedResults = combinedResults.union(infernalResults[i].seqTracrs.keys())\n",
    "    print(\"Round %i found %i more results for a total of %i = %.2f %%\" % \n",
    "          (i, len(combinedResults)-beforeNum,len(combinedResults),\n",
    "          len(combinedResults)/float(len(casRelatedProteins))*100))\n",
    "#     for seqID,clusterIDs in infernalResults[i].seqTracrs.items():\n",
    "#         nuclSeq = casOperons[seqID].seq\n",
    "#         for clusterID in clusterIDs:\n",
    "#             tracr = infernalResults[i].seqTracrs[seqID][clusterID]\n",
    "#             rec = SeqRecord(nuclSeq.seq[tracr.location.start:tracr.location.end], id=seqID+\"___\"+clusterID, name=\"\", description='')\n",
    "#             write(rec,allResults,\"fasta\")\n",
    "# allResults.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateColors(infernalResults,casAssemblies,tRound,gene):\n",
    "    clusterCounter, treeColors, colors, usedIDs = Counter(), {}, {}, set()          #,treeMap,revMap, missingIDs = {}, {}, {}, set()\n",
    "    for struct,ids in infernalResults.structMapping.items(): clusterCounter[struct] = len(ids)\n",
    "    \n",
    "    for clusterID in clusterCounter.most_common(len(infernalResults.structMapping)):\n",
    "        idsWithNoColor = infernalResults.structMapping[clusterID[0]].difference(usedIDs)\n",
    "        if len(idsWithNoColor) <= 1 : continue\n",
    "        colors[clusterID]=genColor()\n",
    "        for protID in idsWithNoColor: treeColors[protID] = colors[clusterID]\n",
    "        usedIDs = usedIDs.union(infernalResults.structMapping[clusterID[0]])\n",
    "    dump(treeColors,open(\"pickles/%s_StructureResultsTreeColors_Round%i.p\" % (gene,tRound),'wb'))\n",
    "    dump(colors,    open(\"pickles/%s_StructureResultsColors_Round%i.p\"     % (gene,tRound),'wb'))\n",
    "    print(\"In round %i, %i assmebly had a predicted tracr (%.1f %%) with %i tracrRNA Structures\" % \n",
    "         (tRound,len(usedIDs),len(usedIDs)/float(len(casAssemblies))*100,len(colors)))\n",
    "    print(\"\\t%i still remaining\" % (len(set(casAssemblies.keys()).difference(usedIDs))))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from InfernalResults import generateColors\n",
    "tRound = 1\n",
    "#infernalResults = ProcessInfernal(tRound,gene) # Results from the last structural search\n",
    "generateColors(infernalResults,casRelatedAssemblies,tRound,gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingIDs = set(casRelatedAssemblies.keys()).difference(combinedResults)\n",
    "clusteredResults = processClusterFile(\"clusters/%s-Like-clustered.faa.clstr\" % (gene))\n",
    "counter = 0\n",
    "casIDs = set(casRelatedAssemblies.keys())\n",
    "for protID in missingIDs:\n",
    "    cluster= clusteredResults.revMap[protID]\n",
    "    if len(clusteredResults[cluster].members)==1: continue\n",
    "    longestCRISPR = ''\n",
    "    maxRepeats = 0\n",
    "    for member in clusteredResults[cluster].members:\n",
    "        operon = casOperons[member].crispr[member]\n",
    "        crType = 'pilerCR'\n",
    "        if crType not in operon: crType = 'minCED'\n",
    "        locus = operon[crType]\n",
    "        if len(locus.repeatCoords) > maxRepeats:\n",
    "            longestCRISPR = member\n",
    "            maxRepeats = len(locus.repeatCoords)\n",
    "    counter +=1\n",
    "    casIDs.remove(protID)\n",
    "    casIDs.add(longestCRISPR)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = {}\n",
    "for protID in casIDs: corrected[protID[:protID.rfind(\"_\")]] = protID \n",
    "casIDs = corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newCasRepFile = open(\"assemblies/Cas9_Representative_Assemblies_2.fasta\",\"w\")\n",
    "allNuclSeqs = {}\n",
    "counter = 0\n",
    "for rec in parse(\"assemblies/All_Cas9_Representative_Assemblies.fasta\",\"fasta\"):\n",
    "    if rec.id in casIDs:\n",
    "        rec.id = casIDs[rec.id]\n",
    "        chrAsmName = \"assemblies/pseudoChromos/%s.fasta\" % (rec.id)\n",
    "        if not path.exists(chrAsmName):\n",
    "            with open(chrAsmName,'w') as fh: write(rec,fh,\"fasta\")\n",
    "        write(rec,newCasRepFile,'fasta')\n",
    "        try: length = len(casOperons[rec.id].seq)\n",
    "        except: \n",
    "            counter+=1\n",
    "            locus = casOperons[rec.id]\n",
    "            setattr(locus,'seq',rec)\n",
    "            locus.seq = rec\n",
    "dump(casOperons, \"pickles/%s_Operons.p\" % gene)       \n",
    "newCasRepFile.close()  \n",
    "counter,len(casIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head assemblies/Cas9_Representative_Assemblies_2.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 2\n",
    "# casOperons = load(open(\"pickles/casOperonDataStructureW%s.p\" % gene,\"rb\"))\n",
    "clusterCMD = \"\"\"\n",
    "cd-hit-est -i sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta -o sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta -M 0 -d 0 -c .90 -s .9 -sc 1\n",
    "\"\"\"\n",
    "for clusterID, protIDs in revMap.items():\n",
    "    with open('sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta' % (gene,tRound,clusterID),'w') as clusterFile:\n",
    "        for protID in protIDs:\n",
    "            baseID = protID[:protID.rfind(\"_\")]\n",
    "            tracr = infernalResults.seqTracrs[baseID][clusterID]\n",
    "            chrAsmName = \"assemblies/pseudoChromos/%s.fasta\" % (protID)\n",
    "            seq = fasta_index(chrAsmName,\"fasta\")[protID]\n",
    "            if tracr.location.start > tracr.location.end: \n",
    "                temp = tracr.location.start\n",
    "                tracr.location.start = tracr.location.end\n",
    "                tracr.location.end = temp\n",
    "            newSeq = seq.seq[tracr.location.start:tracr.location.end].upper()\n",
    "            seq.seq = newSeq\n",
    "            seq.description = \"\"\n",
    "            write(seq,clusterFile,\"fasta\")\n",
    "    seqs = fasta_index(\"sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta\" % (gene,tRound,clusterID),\"fasta\")\n",
    "    if len(seqs) == 1 :continue\n",
    "    os.system(clusterCMD % (gene,tRound,clusterID,gene,tRound,clusterID))\n",
    "    print(\"There are %i TRACRs in %s\" % (len(seqs),clusterID))\n",
    "    clusteredResults = processClusterFile(\"sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta.clstr\" % (gene,tRound,clusterID))\n",
    "    for cluster,clusterSeqIDs in clusteredResults.items():\n",
    "        if len(clusterSeqIDs.members) == 1: continue \n",
    "        if len(clusterSeqIDs.members) == 2: \n",
    "            s1, s2 = list(clusterSeqIDs.members.keys())\n",
    "            if clusterSeqIDs.members[s1] == 100.0 or clusterSeqIDs.members[s2] == 100.0: continue\n",
    "        with open(\"conseqs%i/%s_%s.fasta\" % (tRound,clusterID,cluster.replace(\"Cluster \",\"\")),\"w\") as fh:\n",
    "            for tracrSeqID in clusterSeqIDs.members:\n",
    "                write(seqs[tracrSeqID],fh,\"fasta\")\n",
    "    os.system(\"rm sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta\" % (gene,tRound,clusterID,gene,tRound,clusterID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAssemblies = fasta_index(\"assemblies/All_%s_Representative_Assemblies.fasta\" % (gene),'fasta')\n",
    "len(allAssemblies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakPoints = set()\n",
    "for i in range(0,len(allAssemblies),500): breakPoints.add(i)\n",
    "breakPoints.remove(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='everything'>Doing EVERYTHING at the same time!</a></h2>\n",
    "\n",
    "[Home](#libraries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     locus.annotate(casRelatedAssemblies[protID], chrAsmName)\n",
    "#     if locus.hasNRegion: \n",
    "#         nCounter += 1\n",
    "#         hasNRegionSet.add(protID)\n",
    "#     allLoci[protID] = locus\n",
    "    \n",
    "#     #Step 2c\n",
    "#     tmpFasta = open(\"tmp/possibleTracrs.fasta\",\"w\")\n",
    "    \n",
    "    #Step 2d\n",
    "    chrRec = fasta_index(chrAsmName,\"fasta\")\n",
    "    chrSequence = str(chrRec[list(chrRec.keys())[0]].seq)\n",
    "#     terminusSeqs, index = locus.getTerminusRepeats(chrSequence,index)\n",
    "#     tmpFasta.write(terminusSeqs)\n",
    "    \n",
    "#     #Collect some stats\n",
    "# #     startCoord = locus.repeatCoords[0]\n",
    "# #     endCoord = locus.repeatCoords[-1]\n",
    "# #     seqlen = len(casRelatedAssemblies[protID])\n",
    "# #     minDist = min(seqlen-startCoord.start,seqlen-startCoord.end,seqlen-endCoord.start,seqlen-endCoord.end)\n",
    "# #     minDist =  min(minDist,startCoord.start,startCoord.end,endCoord.start,endCoord.end)\n",
    "\n",
    "#     ##Step 2e - Write sequence surounding hits to the fasta file\n",
    "#     for rec in boundaryHits: index = getSurroundingSequence(tmpFasta,index,chrSequence,rec,500)\n",
    "    \n",
    "#     ##Step 2f - Look for terminators in the possible tracrRNAs\n",
    "#     tmpFasta.close()\n",
    "#     cmd = \"~/bin/Arnold/erpin ~/bin/Arnold/rho-indep.epn tmp/possibleTracrs.fasta -1,4 -add 1 4 2 -pcw 1 -cutoff 100% >tmp/rhoInd.out\"\n",
    "#     system(cmd)\n",
    "    \n",
    "#     ##Setp 2j - process the terminators that were found\n",
    "#     erpOut = ErpinOut()\n",
    "#     if len(erpOut.terminators)==0: \n",
    "#         print (\"\\nThis ref has nothing: %s\\n\" % protID)\n",
    "#         noPredictedTracr.append(protID)\n",
    "#         if locus.hasNRegion: n_and_no_possibles +=1\n",
    "#     else: newSolutions[protID] = erpOut\n",
    "\n",
    "# dump(newSolutions, open(\"pickles/%s_predictedTracrRNAs.p\" % (gene), \"wb\"))\n",
    "numPos, numTerminators, tracrSeqDict = {}, {}, {}\n",
    "newSolutions = load(open(\"pickles/%s_predictedTracrRNAs.p\" % (gene),\"rb\"))\n",
    "index = 0\n",
    "sizeDist = []\n",
    "ignoreSol = 0\n",
    "possibleSol = open(\"sequences/%s_predictedTracrRNAs.fasta\" % (gene),\"w\")\n",
    "for ref,psol in newSolutions.items():\n",
    "    for terminator in psol.terminators:\n",
    "        seq = psol.records[terminator.name]\n",
    "        solSize = 0\n",
    "        #                               ANTI-REPEAT############################A\n",
    "            #############################RC-ANTI-REPEAT\n",
    "        if terminator.upstream and not terminator.strand: tracrSeq = seq[terminator.Rholocation.start-1:].upper()\n",
    "        elif not terminator.upstream and terminator.strand: tracrSeq = seq[:terminator.Rholocation.end].upper()\n",
    "        else: continue #We may have found a termination signal but it is on the wrong strand to code the anti-repeat\n",
    "        solSize = len(tracrSeq)\n",
    "        sizeDist.append(solSize)\n",
    "        if solSize>350 or tracrSeq.count(\"N\")>=4:\n",
    "            ignoreSol+=1\n",
    "            continue\n",
    "        index += 1\n",
    "        tracrSeqDict[\"%s_%i\" % (ref,index)] = tracrSeq\n",
    "        possibleSol.write(\">%s_%i\\n%s\\n\" % (ref,index,tracrSeq))\n",
    "\n",
    "possibleSol.close()\n",
    "print (\"Ignored %i solutions\" % ignoreSol)\n",
    "print (\"Done\", index, \"possible solutions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casOperons = load(open(\"pickles/casOperonDataStructureW%s.p\" % gene,\"rb\"))\n",
    "moreThan1Array = 0\n",
    "nminced,multicounter = 0,0\n",
    "for asmBase,asmOperon in casOperons.casOperon.items():\n",
    "#     for key in asmOperon.crisprs:\n",
    "        \n",
    "    if len(asmOperon.crisprs) > 1: multicounter += 1\n",
    "    crisprs = asmOperon.crisprs[list(asmOperon.crisprs.keys())[0]]\n",
    "    \n",
    "    if 'pilerCR' not in crisprs: \n",
    "        print(asmBase)\n",
    "        print(crisprs)\n",
    "        break\n",
    "        nminced+=1; continue\n",
    "    \n",
    "    moreThan1Array += int(len(crisprs['pilerCR'].consensusRepeat)>1)\n",
    "crlocus = casOperons.casOperon['GCF_000024805.1'].crisprs['NC_013440.1_ORF5729']['pilerCR']\n",
    "moreThan1Array,nminced,multicounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allClusters, allClusterSeqIDs = {},{}\n",
    "for line in open(\"clusters/%s_predictedTracrRNAs.grouped.fasta.clstr\" % (gene)):\n",
    "    if \">Cluster\" in line: clusterID = line.strip().replace(\">\",\"\")\n",
    "    else:\n",
    "        seqID = line[line.find(\">\")+1:line.find(\"...\")] \n",
    "        seqID = seqID[:seqID.rfind(\"_\")]\n",
    "        try:allClusters[clusterID].add(seqID)\n",
    "        except:allClusters[clusterID]=set([seqID])\n",
    "        try:allClusterSeqIDs[seqID].add(clusterID)\n",
    "        except:allClusterSeqIDs[seqID]=set([clusterID])\n",
    "xs,ys,zs=[],[],[]\n",
    "remove=set()\n",
    "colors,TreeColors={},{}\n",
    "clusterDist=[]\n",
    "for cluster, ids in allClusters.items():\n",
    "    clusterDist.append(len(ids))\n",
    "    if len(ids) < 2: remove.add(cluster)\n",
    "    else:\n",
    "        colors[cluster]=color()\n",
    "        for id in ids:TreeColors[id.replace(\".\",\"_\")] = colors[cluster]\n",
    "for id in remove: del allClusters[id]\n",
    "\n",
    "print (\"\\tTotal number of clusters:\",len(allClusters))\n",
    "print (\"\\tNumber of nodes covered:\",len(TreeColors))\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# xs.append(len(allClusters))\n",
    "# ys.append(len(TreeColors))\n",
    "# zs.append(i)\n",
    "# ax.scatter(ys,xs,zs)    \n",
    "# # xs.reverse()\n",
    "# # ys.reverse()\n",
    "# # plt.plot(xs, ys, 'ro')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $gene\n",
    "cd-hit-est -i sequences/$1_predictedTracrRNAs.fasta -o sequences/$1_predictedTracrRNAs.grouped.fasta -M 0 -d 0 -c .90 -T 0 >logs/$1_tracrClusterLog.log\n",
    "tail -n 8 logs/$1_tracrClusterLog.log > logs/clusterInfo\n",
    "head -n 1 logs/clusterInfo; rm logs/clusterInfo\n",
    "mv sequences/$1_predictedTracrRNAs.grouped.fasta.clstr clusters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allClusters, allClusterSeqIDs = {},{}\n",
    "for line in open(\"clusters/%s_predictedTracrRNAs.grouped.fasta.clstr\" % (gene)):\n",
    "    if \">Cluster\" in line: clusterID = line.strip().replace(\">\",\"\")\n",
    "    else:\n",
    "        seqID = line[line.find(\">\")+1:line.find(\"...\")] \n",
    "        seqID = seqID[:seqID.rfind(\"_\")]\n",
    "        try:allClusters[clusterID].add(seqID)\n",
    "        except:allClusters[clusterID]=set([seqID])\n",
    "        try:allClusterSeqIDs[seqID].add(clusterID)\n",
    "        except:allClusterSeqIDs[seqID]=set([clusterID])\n",
    "xs,ys,zs=[],[],[]\n",
    "remove=set()\n",
    "colors,TreeColors={},{}\n",
    "clusterDist=[]\n",
    "for cluster, ids in allClusters.items():\n",
    "    clusterDist.append(len(ids))\n",
    "    if len(ids) < 2: remove.add(cluster)\n",
    "    else:\n",
    "        colors[cluster]=color()\n",
    "        for id in ids:TreeColors[id.replace(\".\",\"_\")] = colors[cluster]\n",
    "for id in remove: del allClusters[id]\n",
    "\n",
    "print (\"\\tTotal number of clusters:\",len(allClusters))\n",
    "print (\"\\tNumber of nodes covered:\",len(TreeColors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpDict = {}\n",
    "tracrSeqDict = fasta_index(\"sequences/%s_predictedTracrRNAs.fasta\" % (gene),\"fasta\")\n",
    "for id,seq in tracrSeqDict.items(): tmpDict[id[:id.rfind(\"_\")]]=str(seq.seq).upper()\n",
    "tracrSeqDict = tmpDict  \n",
    "for cluster, seqIDList in allClusters.items():\n",
    "    clusterFileName = \"conseqs0/\"+cluster.replace(\" \",\"_\")+\".fasta\"\n",
    "    fh = open(clusterFileName,\"w\")\n",
    "    clusterStats = []\n",
    "    for seqID in seqIDList: clusterStats.append(len(tracrSeqDict[seqID]))\n",
    "    clusterStats = Series(clusterStats)\n",
    "    keepSeqs = clusterStats[~((clusterStats-clusterStats.mean()).abs() > clusterStats.std())]\n",
    "    minSeq, maxSeq = keepSeqs.min(), keepSeqs.max()\n",
    "    index=0\n",
    "    for seqID in seqIDList: \n",
    "        seqLen = len(tracrSeqDict[seqID])\n",
    "        if seqLen >= minSeq and seqLen <= maxSeq:\n",
    "            index+=1\n",
    "            fh.write(\">%s\\n%s\\n\" % (seqID,tracrSeqDict[seqID]))\n",
    "    fh.close()\n",
    "    if index <= 1: system(\"rm %s\" % (clusterFileName)); continue\n",
    "    \n",
    "    os.system(\"cd-hit-est -i %s -o %s_cluster -M 0 -d 0 -c .90 -T 0 -sc 1 >/dev/null\" % (clusterFileName,clusterFileName))\n",
    "    clusteredResults = processClusterFile(\"%s_cluster.clstr\" % (clusterFileName))\n",
    "    fh = open(clusterFileName,\"w\")\n",
    "    index = 0 \n",
    "    for seqID,direction in clusteredResults.filter():\n",
    "        index +=1\n",
    "        if direction: fh.write(\">%s\\n%s\\n\" % (seqID,str(tracrSeqDict[seqID])))\n",
    "        else: fh.write(\">%s\\n%s\\n\" % (seqID, reverse_complement(tracrSeqDict[seqID])))\n",
    "    fh.close()\n",
    "    if index <= 1: system(\"rm %s\" % (clusterFileName))\n",
    "#     else: print( clusterFileName,\"(\",index,\"/\",len(seqIDList), \")[%i,%i]\" % (minSeq,maxSeq),clusterStats.std() )\n",
    "    system(\"rm %s_cluster*\" % (clusterFileName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Structure Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 0\n",
    "infernalResults = ProcessInfernal(tRound,gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 1\n",
    "infernalResults = ProcessInfernal(tRound,gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for structures overlapping the same sequence to combine the sequences into the same structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infernalResults = ProcessInfernal(tRound,gene)\n",
    "\n",
    "clusterCounter,treeMap,revMap, missingIDs = {}, {}, {}, set()\n",
    "for struct,ids in infernalResults.structMapping.items(): clusterCounter[struct] = len(ids)\n",
    "missingCounter = 0\n",
    "for protID in casRelatedAssemblies:\n",
    "    baseID = protID[:protID.rfind(\"_\")]\n",
    "    if baseID not in infernalResults.seqTracrs: \n",
    "        missingCounter += 1; \n",
    "        missingIDs.add(protID)\n",
    "        continue\n",
    "    biggestCluster =  findBiggestCluster(infernalResults.seqTracrs[baseID].keys(),clusterCounter)\n",
    "    treeMap[protID] = biggestCluster\n",
    "    try: revMap[biggestCluster].add(protID)\n",
    "    except: revMap[biggestCluster] = set([protID])\n",
    "missingCounter, len(revMap)\n",
    "treeColors,colors = {},{}\n",
    "for cluster, protIDs in revMap.items():\n",
    "    colors[cluster]=color()\n",
    "    for protID in protIDs: treeColors[protID] = colors[cluster]\n",
    "dump(treeColors,open(\"pickles/%s_StructureResultsTreeColors_Round%i.p\" % (gene,tRound),\"wb\"))\n",
    "dump(colors,    open(\"pickles/%s_StructureResultsColors_Round%i.p\"     % (gene,tRound),\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 2\n",
    "# casOperons = load(open(\"pickles/casOperonDataStructureW%s.p\" % gene,\"rb\"))\n",
    "clusterCMD = \"\"\"\n",
    "cd-hit-est -i sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta -o sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta -M 0 -d 0 -c .90 -s .9 -sc 1\n",
    "\"\"\"\n",
    "for clusterID, protIDs in revMap.items():\n",
    "    with open('sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta' % (gene,tRound,clusterID),'w') as clusterFile:\n",
    "        for protID in protIDs:\n",
    "            baseID = protID[:protID.rfind(\"_\")]\n",
    "            tracr = infernalResults.seqTracrs[baseID][clusterID]\n",
    "            chrAsmName = \"assemblies/pseudoChromos/%s.fasta\" % (protID)\n",
    "            seq = fasta_index(chrAsmName,\"fasta\")[protID]\n",
    "            if tracr.location.start > tracr.location.end: \n",
    "                temp = tracr.location.start\n",
    "                tracr.location.start = tracr.location.end\n",
    "                tracr.location.end = temp\n",
    "            newSeq = seq.seq[tracr.location.start:tracr.location.end].upper()\n",
    "            seq.seq = newSeq\n",
    "            seq.description = \"\"\n",
    "            write(seq,clusterFile,\"fasta\")\n",
    "    seqs = fasta_index(\"sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta\" % (gene,tRound,clusterID),\"fasta\")\n",
    "    if len(seqs) == 1 :continue\n",
    "    os.system(clusterCMD % (gene,tRound,clusterID,gene,tRound,clusterID))\n",
    "    print(\"There are %i TRACRs in %s\" % (len(seqs),clusterID))\n",
    "    clusteredResults = processClusterFile(\"sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta.clstr\" % (gene,tRound,clusterID))\n",
    "    for cluster,clusterSeqIDs in clusteredResults.items():\n",
    "        if len(clusterSeqIDs.members) == 1: continue \n",
    "        if len(clusterSeqIDs.members) == 2: \n",
    "            s1, s2 = list(clusterSeqIDs.members.keys())\n",
    "            if clusterSeqIDs.members[s1] == 100.0 or clusterSeqIDs.members[s2] == 100.0: continue\n",
    "        with open(\"conseqs%i/%s_%s.fasta\" % (tRound,clusterID,cluster.replace(\"Cluster \",\"\")),\"w\") as fh:\n",
    "            for tracrSeqID in clusterSeqIDs.members:\n",
    "                write(seqs[tracrSeqID],fh,\"fasta\")\n",
    "    os.system(\"rm sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta\" % (gene,tRound,clusterID,gene,tRound,clusterID))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 2\n",
    "infernalResults = ProcessInfernal(tRound,gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRound = 3\n",
    "# casOperons = load(open(\"pickles/casOperonDataStructureW%s.p\" % gene,\"rb\"))\n",
    "clusterCMD = \"\"\"\n",
    "cd-hit-est -i sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta -o sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta -M 0 -d 0 -c .85 -s .9 -sc 1\n",
    "\"\"\"\n",
    "for clusterID, protIDs in revMap.items():\n",
    "    with open('sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta' % (gene,tRound,clusterID),'w') as clusterFile:\n",
    "        for protID in protIDs:\n",
    "            baseID = protID[:protID.rfind(\"_\")]\n",
    "            tracr = infernalResults.seqTracrs[baseID][clusterID]\n",
    "            chrAsmName = \"assemblies/pseudoChromos/%s.fasta\" % (protID)\n",
    "            seq = fasta_index(chrAsmName,\"fasta\")[protID]\n",
    "            if tracr.location.start > tracr.location.end: \n",
    "                temp = tracr.location.start\n",
    "                tracr.location.start = tracr.location.end\n",
    "                tracr.location.end = temp\n",
    "            newSeq = seq.seq[tracr.location.start:tracr.location.end].upper()\n",
    "            seq.seq = newSeq\n",
    "            seq.description = \"\"\n",
    "            write(seq,clusterFile,\"fasta\")\n",
    "    seqs = fasta_index(\"sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta\" % (gene,tRound,clusterID),\"fasta\")\n",
    "    if len(seqs) == 1 :continue\n",
    "    os.system(clusterCMD % (gene,tRound,clusterID,gene,tRound,clusterID))\n",
    "    print(\"There are %i TRACRs in %s\" % (len(seqs),clusterID))\n",
    "    clusteredResults = processClusterFile(\"sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta.clstr\" % (gene,tRound,clusterID))\n",
    "    for cluster,clusterSeqIDs in clusteredResults.items():\n",
    "        if len(clusterSeqIDs.members) == 1: continue \n",
    "        if len(clusterSeqIDs.members) == 2: \n",
    "            s1, s2 = list(clusterSeqIDs.members.keys())\n",
    "            if clusterSeqIDs.members[s1] == 100.0 or clusterSeqIDs.members[s2] == 100.0: continue\n",
    "        with open(\"conseqs%i/%s_%s.fasta\" % (tRound,clusterID,cluster.replace(\"Cluster \",\"\")),\"w\") as fh:\n",
    "            for tracrSeqID in clusterSeqIDs.members:\n",
    "                write(seqs[tracrSeqID],fh,\"fasta\")\n",
    "    os.system(\"rm sequences/tracrs/%s_Round%i_%s_TracrRNAs.fasta sequences/tracrs/%s_Round%i_%s_TracrRNAs.grouped.fasta\" % (gene,tRound,clusterID,gene,tRound,clusterID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBiggestCluster(clusters, clusterMap): return Counter(dict((k, clusterMap[k]) for k in (clusters))).most_common(1)[0][0] \n",
    "clusterCounter,treeMap,revMap, missingIDs = {}, {}, {}, set()\n",
    "for struct,ids in infernalResults.structMapping.items(): clusterCounter[struct] = len(ids)\n",
    "missingCounter = 0\n",
    "for protID in casRelatedAssemblies:\n",
    "    baseID = protID[:protID.rfind(\"_\")]\n",
    "    if baseID not in infernalResults.seqTracrs: \n",
    "        missingCounter += 1; \n",
    "        missingIDs.add(protID)\n",
    "        continue\n",
    "    biggestCluster =  findBiggestCluster(infernalResults.seqTracrs[baseID].keys(),clusterCounter)\n",
    "    treeMap[protID] = biggestCluster\n",
    "    try: revMap[biggestCluster].add(protID)\n",
    "    except: revMap[biggestCluster] = set([protID])\n",
    "missingCounter, len(revMap)\n",
    "treeColors,colors = {},{}\n",
    "for cluster, protIDs in revMap.items():\n",
    "    colors[cluster]=color()\n",
    "    for protID in protIDs: treeColors[protID] = colors[cluster]\n",
    "dump(treeColors,open(\"pickles/%s_StructureResultsTreeColors_Round%i.p\" % (gene,tRound),\"wb\"))\n",
    "dump(colors,    open(\"pickles/%s_StructureResultsColors_Round%i.p\"     % (gene,tRound),\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newSolutions = load(open(\"pickles/%s_predictedTracrRNAs.p\" % (gene), \"rb\"))\n",
    "hasPossibles = 0\n",
    "for protID in missingIDs: hasPossibles += int(protID in newSolutions)\n",
    "hasPossibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#casOperons = load(open(\"pickles/casOperonDataStructureW%s.p\" % gene,\"rb\"))\n",
    "for protID in missingIDs: \n",
    "    if protID not in newSolutions: continue\n",
    "        \n",
    "    genomicAsmName = casOperons.revMap[protID] \n",
    "    protOperon = casOperons.casOperon[genomicAsmName]\n",
    "    protCRISPR = protOperon.crisprs[protID]\n",
    "    if 'pilerCR' in protCRISPR: locus = protCRISPR['pilerCR']\n",
    "    else:\n",
    "        locus = protCRISPR['minCED']\n",
    "        locus.calc_consensus() \n",
    "        \n",
    "    print(protID,locus.consensusRepeat)\n",
    "    rho = newSolutions[protID]\n",
    "    for reqID, seq in rho.records.items():\n",
    "        print(reqID,\"\\t\",\"%.2f\" % CalcPercIdent(locus.consensusRepeat[0],seq),len(seq))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = rho.terminators[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyFunctions import Coordinate\n",
    "class ErpinOut:\n",
    "    def __init__(self, outfile=\"tmp/rhoInd.out\", inputfile=\"tmp/possibleTracrs.fasta\"):\n",
    "        self.numRecords = 0\n",
    "        self.terminators = []\n",
    "        self.records={}\n",
    "        for rec in parse(inputfile,\"fasta\"):\n",
    "            self.numRecords += 1\n",
    "            self.records[rec.id]=str(rec.seq)\n",
    "        with open(outfile) as file:\n",
    "            for i in range(9): file.readline()\n",
    "            capture = False\n",
    "            for line in file:\n",
    "                if capture: \n",
    "                    line = line.strip().replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \")\n",
    "                    self.terminators.append(RhoIndTerminator(seqName,line.split(\" \")))\n",
    "                capture = (\">\" in line)\n",
    "                if capture: seqName = line.strip().replace(\">\",\"\")\n",
    "                    \n",
    "class RhoIndTerminator:\n",
    "    def __init__(self,name,info):\n",
    "        print(\"This it the sequence:\",str(info))\n",
    "        self.name = name\n",
    "        self.strand = (info[0]==\"FW\")\n",
    "        start, end = info[2].split(\"..\")\n",
    "        self.Rholocation = Coordinate(start,end)\n",
    "        self.fwd = int(self.name[-1]) % 2 != 0\n",
    "    def __str__(self): return \"%s\\t%s\\t%s\\t%s\\t\" % (self.name,str(self.strand),str(self.Rholocation),str(self.fwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protID = \"NZ_KV814503.1_ORF2438\"\n",
    "conRepeat = \"sequences/conRepeats/%s.fasta\" % (protID)\n",
    "write([SeqRecord(id=protID,description='',seq=Seq(locus.consensusRepeat[0]))],conRepeat,\"fasta\")\n",
    "chrAsmName = \"assemblies/pseudoChromos/%s.fasta\" % (protID)\n",
    "blast_results = parseSingleBLAST(BLAST_short(conRepeat, chrAsmName, \"blastout/conRepeats/%s.xml\" % (protID)))\n",
    "boundaryHits,crRNALen = locus.checkArrayBoundaries(blast_results)\n",
    "\n",
    "chrRec = fasta_index(chrAsmName,\"fasta\")\n",
    "chrSequence = str(chrRec[list(chrRec.keys())[0]].seq)\n",
    "index = 0\n",
    "terminusSeqs, index = locus.getTerminusRepeats(chrSequence,index)\n",
    "print(\"\")\n",
    "print(locus.consensusRepeat)\n",
    "print(\"\")\n",
    "for line in terminusSeqs.split(\"\\n\"): print(line,\" \",len(line))\n",
    "tmpFasta = open(\"tmp/possibleTracrs.fasta\",\"w\")\n",
    "tmpFasta.write(terminusSeqs)\n",
    "\n",
    "tmpFasta.close()\n",
    "cmd = \"~/bin/Arnold/erpin ~/bin/Arnold/rho-indep.epn tmp/possibleTracrs.fasta -1,4 -add 1 4 2 -pcw 1 -cutoff 100% >tmp/rhoInd.out\"\n",
    "system(cmd)\n",
    "\n",
    "##Setp 2j - process the terminators that were found\n",
    "erpOut = ErpinOut()\n",
    "if len(erpOut.terminators)==0: \n",
    "    print(\"\\nThis ref has nothing: %s\\n\" % protID)\n",
    "else: \n",
    "    for terminator in erpOut.terminators:\n",
    "        tracrSeq=\"\"\n",
    "        if terminator.fwd and not terminator.strand: #Terminator must be on the anti-sense strand\n",
    "            ############################ANTI-REPEAT\n",
    "            ############################RC-Anti\n",
    "            print(\"Upstream terminator:\",str(terminator))\n",
    "            tracrSeq = s1[terminator.Rholocation.start-1:].upper()\n",
    "        elif not terminator.fwd and terminator.strand: \n",
    "            print(\"Downstream terminator:\",str(terminator))\n",
    "            tracrSeq = s1[:terminator.Rholocation.end].upper()\n",
    "        solSize = len(tracrSeq)\n",
    "        print (tracrSeq,solSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 0 - Predictions From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.find(RC('GCTGGGAATCAATCACCAATCCCCTTTGATATACTG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prpath = \"/mnt/research/germs/shane/databases/crisprs/pilerCR/genbank/GCA_003480745.1.pcrout\"\n",
    "cr = PilerCRReader(prpath)['QUJS01000001.1']\n",
    "print(cr.consensusRepeats)\n",
    "protID = 'QUJS01000001.1_ORF40881'\n",
    "conRepeatFP = \"sequences/conRepeats/%s.fasta\" % (protID)\n",
    "chrAsmName = \"assemblies/pseudoChromos/%s.fasta\" % (protID)\n",
    "print(conRepeatFP)\n",
    "# print()\n",
    "conRepeats = open(conRepeatFP,'w')\n",
    "conRepeats.write(cr.repeatSeqs(protID))\n",
    "conRepeats.close()\n",
    "blastResults = BLAST_short(conRepeatFP, chrAsmName, \"blastout/conRepeats/%s.xml\" % (protID))\n",
    "blast_results = parseBLAST(blastResults)\n",
    "for res in blast_results: print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(\"sequences/testRC.fasta\",\"w\")\n",
    "from Bio.SeqIO import parse,write\n",
    "for rec in parse(\"sequences/KnownTracrRNAs.fa\",\"fasta\"):\n",
    "    write(rec,fh,\"fasta\")\n",
    "    rec.id = rec.id+\"RevComp\"\n",
    "    rec.seq = rec.seq.reverse_complement()\n",
    "    write(rec,fh,\"fasta\")\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignSequence(s1,locus.consensusRepeat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RC(seq): return str(Seq(seq).reverse_complement())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = erpOut.terminators[0]\n",
    "t2 = erpOut.terminators[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(t2.Rholocation),len(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(locus.consensusRepeat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.Rholocation.end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solSize = 0\n",
    "tracrSeq = \"\"\n",
    "if t1.fwd and not t1.strand: #Terminator must be on the anti-sense strand\n",
    "    ############################ANTI-REPEAT\n",
    "    ############################RC-Anti\n",
    "    tStart = t1.Rholocation.start-1\n",
    "    tracrSeq = s1[tStart:].upper()\n",
    "    solSize = len(tracrSeq)\n",
    "elif not t1.fwd and t1.strand: \n",
    "    tracrSeq = s1[:t1.Rholocation.end].upper()\n",
    "print (tracrSeq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat tmp/rhoInd.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crispr.terminators = []\n",
    "crispr.getAntiRepeatCandidates(open(\"tmp/possibleTracrs.fasta\",\"w\"), operon.getSeq())\n",
    "res = system(\"~/bin/Arnold/erpin ~/bin/Arnold/rho-indep.epn tmp/possibleTracrs.fasta -1,4 -add 1 4 2 -pcw 3.0 -cutoff 100% >tmp/rhoInd.out\")\n",
    "erpOut = ErpinOut()\n",
    "len(erpOut.terminators), crispr.getTracrRNA_Candidates(erpOut,open(\"test.txt\",'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAsm = fasta_index(\"\" % (id), \"fasta\")\n",
    "for id,rec in casRelatedAssemblies.items():\n",
    "    if path.exists(\"assemblies/pseudoChromos/%s.fasta\" % (id)):continue\n",
    "    with open(\"assemblies/pseudoChromos/%s.fasta\" % (id),\"w\") as fh: write(allAsm[id],fh,\"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBiggestCluster(clusters, clusterMap): return Counter(dict((k, clusterMap[k]) for k in (clusters))).most_common(1)[0][0] \n",
    "\n",
    "newColors,newColorMap, TreeColors,newIDs = {}, {}, knownTracrRNAs.copy(), set()\n",
    "startLen = len(TreeColors)\n",
    "print \"Started with %i tracrRNAs\" % (startLen)\n",
    "for seqID in newTracrRNAs:\n",
    "#     print \"Next\",seqID\n",
    "    #Get all the clusters the ID is associated with:\n",
    "    clusters = infernalResults[seqID]\n",
    "    \n",
    "    #Get all of the IDs associated with those clusters\n",
    "    clusterIDS = set()\n",
    "    for cluster in clusters: clusterIDS = clusterIDS.union(infernalResults[cluster])\n",
    "        \n",
    "    #Check to see if there is overlap betweeb the IDs of the known and the IDs of the predicted for this new tracr\n",
    "    overlappingIDs = clusterIDS.intersection(knownTracrRNAs)\n",
    "    \n",
    "    if len(overlappingIDs)>0:#If there is overlap\n",
    "        #Get the cluster color(s) of the overlapping IDs\n",
    "        colors = set()\n",
    "        for o_id in overlappingIDs: colors.add(knownTracrRNAs[o_id])\n",
    "            \n",
    "        #Choose the biggest color\n",
    "        id_color = findBiggestCluster(colors,knownTracrColorCounter)\n",
    "\n",
    "    else: #No overlap, choose the best color from new clusters\n",
    "        biggestCluster = findBiggestCluster(clusters,unknownClusterCounter)\n",
    "        try: id_color = newColors[biggestCluster]; newColorMap[newColors[biggestCluster]].add(seqID)\n",
    "        except: id_color = newColors[biggestCluster] = genColor(); newColorMap[newColors[biggestCluster]] = set([seqID])\n",
    "        newIDs.add(seqID)\n",
    "    TreeColors[seqID] = id_color\n",
    "\n",
    "print \"Annotated %i/%i\" % (len(TreeColors),len(casRelatedAssemblies))\n",
    "print \"\\t\",len(TreeColors)-startLen, \"found\"\n",
    "print \"\\t\",len(newIDs), \"/\", len(TreeColors)-startLen, \"contain a unique structure\"\n",
    "print \"\\t\",len(newColors), \"/\", len(newColors)+len(knownTracrColorCounter), \"new clusters\"\n",
    "\n",
    "dump(TreeColors, \"pickles/PredictedTracrRNA_colors.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#annotate)\n",
    "\n",
    "<a id=\"ref\">reference</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crRNALens, crisprLocations, noPredictedTracr, seqLenDist = [],[],[],[]\n",
    "hasNRegionSet,crRNALens, possibleSolutions, newSolutions, index, counter = set(),[], set(), {}, 0, 0\n",
    "allLoci = {}\n",
    "nCounter, n_and_no_possibles = 0,0\n",
    "# novelLoci = pickle.load(open(\"pickles/NovelTracrs.p\",\"rb\"))\n",
    "for protID in casRelatedAssemblies:\n",
    "#     if protID not in novelLoci: continue\n",
    "    #Step 1: Select the CRISPR array from the CRISPR Arrays\n",
    "#     baseID = protID[:protID.find(\"_ORF\")]\n",
    "    if protID not in pilerCR_results and protID not in minCED_results: \n",
    "        die\n",
    "        continue #Missing from both\n",
    "    try: \n",
    "        if protID in pilerCR_results: assemblyLoci = pilerCR_results[protID].values()\n",
    "        else: assemblyLoci = pilerCR_results[baseID].values() #Looking only at the most abundant crispr\n",
    "        for locus in assemblyLoci:\n",
    "            if locus.name == protID: break\n",
    "        if locus.name != baseID: die\n",
    "    except: \n",
    "        try: assemblyLoci = minCED_results[baseID].values()\n",
    "        except: assemblyLoci = minCED_results[protID].values()\n",
    "                 \n",
    "        for locus in assemblyLoci:\n",
    "            if locus.name == baseID: break\n",
    "        if locus.name != baseID: die\n",
    "\n",
    "    write([SeqRecord(id=protID,description='',seq=Seq(locus.consensusRepeat[0]))],\"tmp/consFasta.fa\",\"fasta\")\n",
    "    blast_results = parseSingleBLAST(BLAST_short(\"tmp/consFasta.fa\", \"assemblies/%s.fa\" % (protID), \"tmp/consBlast.xml\"))\n",
    "    \n",
    "    #Step 2b\n",
    "    boundaryHits,crRNALen = locus.checkArrayBoundaries(blast_results)\n",
    "    crRNALens.append(crRNALen)\n",
    "    locus.annotate(casRelatedAssemblies[protID], \"assemblies/%s.fa\" % (protID))\n",
    "    if locus.hasNRegion: \n",
    "        nCounter += 1\n",
    "        hasNRegionSet.add(protID)\n",
    "    allLoci[protID] = locus\n",
    "    \n",
    "    #Step 2c\n",
    "    tmpFasta = open(\"tmp/possibleTracrs.fasta\",\"w\")\n",
    "    \n",
    "    #Step 2d\n",
    "    terminusSeqs, index = locus.getTerminusRepeats(casRelatedAssemblies[protID],index)\n",
    "    tmpFasta.write(terminusSeqs)\n",
    "    \n",
    "    #Collect some stats\n",
    "    startCoord = locus.repeatCoords[0]\n",
    "    endCoord = locus.repeatCoords[-1]\n",
    "    seqlen = len(casRelatedAssemblies[protID])\n",
    "    seqLenDist.append(seqlen)\n",
    "    minDist = min(seqlen-startCoord.start,seqlen-startCoord.end,seqlen-endCoord.start,seqlen-endCoord.end)\n",
    "    minDist =  min(minDist,startCoord.start,startCoord.end,endCoord.start,endCoord.end)\n",
    "    crisprLocations.append(minDist)\n",
    "\n",
    "    ##Step 2e - Write sequence surounding hits to the fasta file\n",
    "    for rec in boundaryHits: index = getSurroundingSequence(tmpFasta,index,casRelatedAssemblies[protID],rec,500)\n",
    "    \n",
    "    ##Step 2f - Look for terminators in the possible tracrRNAs\n",
    "    tmpFasta.close()\n",
    "    cmd = \"~/bin/Arnold/erpin ~/bin/Arnold/rho-indep.epn tmp/possibleTracrs.fasta -1,4 -add 1 4 2 -pcw 1 -cutoff 100% >tmp/rhoInd.out\"\n",
    "    system(cmd)\n",
    "    \n",
    "    ##Setp 2j - process the terminators that were found\n",
    "    erpOut = ErpinOut()\n",
    "    if len(erpOut.terminators)==0: \n",
    "        print \"\\nThis ref has nothing: %s\\n\" % protID\n",
    "        noPredictedTracr.append(protID)\n",
    "        if locus.hasNRegion: n_and_no_possibles +=1\n",
    "    else: \n",
    "        newSolutions[protID] = erpOut\n",
    "        repeatIndex = 0\n",
    "    BLAHBLAH\n",
    "    ## Everything below this point is for getting and annotation a genbank file for the assembly associated with the CRISPR ##\n",
    "    ##Look through terminators\n",
    "    for terminator in erpOut.terminators:\n",
    "        info= terminator.name.split(\"_\")\n",
    "        whereRepeat = (info[1] == \"S\")\n",
    "        start = int(info[-3])\n",
    "        end = int(info[-2])\n",
    "        strand = -1\n",
    "        if terminator.strand == \"+\": strand = 1\n",
    "        if whereRepeat: \n",
    "            tracr_size = end - (end-min(terminator.Rholocation.start, terminator.Rholocation.end))\n",
    "            if tracr_size > 350:continue\n",
    "            repeatFeature = SeqFeature(FeatureLocation(end-min(terminator.Rholocation.start, terminator.Rholocation.end), end), type=\"CDS\", strand=strand)\n",
    "        else: \n",
    "            tracr_size = (start + max(terminator.Rholocation.start, terminator.Rholocation.end)) - start\n",
    "            if tracr_size > 350:continue\n",
    "            repeatFeature = SeqFeature(FeatureLocation(start,start + max(terminator.Rholocation.start, terminator.Rholocation.end)), type=\"CDS\", strand=strand)\n",
    "        fid = \"Theoretical tracrRNA_%i\" % (repeatIndex)\n",
    "        repeatFeature.qualifiers['label'] = [fid]\n",
    "#         locus.orfs.records[baseID].features.append(repeatFeature)\n",
    "        repeatIndex += 1 \n",
    "    \n",
    "    #shift annoations by buffer\n",
    "# #     if not locus.orfs:continue\n",
    "#     locus.orfs.records[baseID].seq = locus.orfs.records[baseID].seq[max(locus.min-500,0):locus.max+500]\n",
    "#     #locus.orfs.records[protID].seq = locus.orfs.records[protID].seq[max(locus.min-500,0):locus.max+500]\n",
    "#     for rec in locus.orfs.records[baseID].features:\n",
    "# #         print \"This is the start:\", rec.location.start - max(locus.min-100,0), rec.location.end - max(locus.min-100,0),rec.location.start,rec.location.end\n",
    "#         rec.location = FeatureLocation(rec.location.start - max(locus.min-500,0), rec.location.end - max(locus.min-500,0))\n",
    "# #         print \"This is the   end:\", rec.location.start, rec.location.end\n",
    "    \n",
    "    # Step 2k Create setup for GB file for Vector NTI\n",
    "#     for id in locus.orfs.records:\n",
    "#         print \"annotations/%s.gb\" % (locus.name)\n",
    "#         fh = open(\"annotations/%s.gb\" % (locus.name),\"w\")\n",
    "#         biopythonID = id[:id.find(\":\")-1] #Biopython limits genbank file ids to 16 characters\n",
    "#         locus.orfs.records[id].id = biopythonID[:16]\n",
    "#         locus.orfs.records[id].name = biopythonID[:16]\n",
    "#         write([locus.orfs.records[id]],fh,'genbank')\n",
    "#         fh.close()\n",
    "print (len(allLoci))\n",
    "pickle.dump(allLoci,open(\"pickles/TracrLoci.p\",\"wb\"))    \n",
    "pickle.dump(newSolutions,open(\"pickles/%s_predictedTracrRNAs.p\" % (gene),\"wb\"))\n",
    "print(\"\\n\\nNumber of proteins with large N region and no terminator / with total large N region: %i / %i\" % (n_and_no_possibles,nCounter))\n",
    "print(\"%i possible solutions in %s references. Nothing found in %i references\" % (index-1, len(newSolutions),len(noPredictedTracr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(numRepeats)\n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('Number of Repeats');\n",
    "plt.title('Repeat Elements in CRISPR Arrays')\n",
    "plt.savefig('images/%s_CRISPR_Repeats.png' % gene)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badIDs = set()\n",
    "for protID in casRelatedAssemblies:\n",
    "    if protID not in pilerCR_results:\n",
    "        crisprResults = PilerCRReader(\"crisprs/%s.pcrout\" % (protID))\n",
    "        baseChrID = protID[:protID.rfind(\"_\")]\n",
    "        if len(crisprResults) > 1: multipleCRISPRS[protID] = crisprResults\n",
    "        try: pilerCR_results[protID] = crisprResults[baseChrID]\n",
    "        except: badIDs.add(protID)\n",
    "len(badIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove=set()\n",
    "for protID in pilerCR_results:\n",
    "    if protID not in casRelatedAssemblies:\n",
    "        print(protID)\n",
    "        remove.add(protID)\n",
    "        \n",
    "for protID in remove: del pilerCR_results[protID]\n",
    "len(pilerCR_results)\n",
    "for protID in badIDs: del casRelatedAssemblies[protID]\n",
    "len(casRelatedAssemblies)\n",
    "aa_s = open(\"proteins/%s-Like-clustered_full.faa\" % (gene),\"w\")\n",
    "fasta = open(\"assemblies/%s_Representative_Assemblies.fasta\" % (gene),\"w\")\n",
    "for id,rec in casRelatedAssemblies.items():\n",
    "    write(rec,aa_s,\"fasta\")\n",
    "    protAsm = fasta_index(\"assemblies/pseudoChromos/%s.fasta\" % (id), \"fasta\")\n",
    "    write(protAsm[id],fasta,\"fasta\")\n",
    "fasta.close()\n",
    "aa_s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqUtils import GC\n",
    "gcRepeats = []\n",
    "for protID, crispr in pilerCR_results.items(): gcRepeats.append(GC(crispr.consensusRepeat[0]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(gcRepeats)\n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('GC Content');\n",
    "plt.title('GC Content of Consensus Repeat')\n",
    "plt.savefig('images/%s_CRISPR_GC.png' % gene)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeatLens = []\n",
    "for protID, crispr in pilerCR_results.items(): repeatLens.append(len(crispr.consensusRepeat[0]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(repeatLens)\n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('Consensus Repeat Length');\n",
    "plt.title('Length of Consensus Repeat in Cas9 Systems')\n",
    "plt.savefig('images/%s_CRISPR_Len.png' % gene)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilerCR_results = load(open(\"pickles/%s_pilerCR_results.p\" % (gene),\"rb\"))\n",
    "assembliesWCrisprs = load(open(\"pickles/allAssemblyCRISPRs.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pilerCRFileName in crisprResultFiles:\n",
    "    protID = pilerCRFileName.replace(\".pcrout\",\"\").replace(\"crisprs/\",\"\")\n",
    "    if protID not in casRelatedAssemblies: continue\n",
    "    mincedFileName = pilerCRFileName.replace(\"pcrout\",\"mnout\")\n",
    "    noMinced = (stat(mincedFileName).st_size == 0)\n",
    "    noPiler = (stat(pilerCRFileName).st_size <= 200)\n",
    "    \n",
    "    if not noMinced and not noPiler:\n",
    "        crisprs_in_both +=1\n",
    "        minCED_results[protID]  = MinCEDReader(mincedFileName)\n",
    "        pilerCR_results[protID] = PilerCRReader(pilerCRFileName)\n",
    "        minCED_results[protID].calulate_consensus_seqs()\n",
    "#         for id,locus in pilercrResults.iteritems():\n",
    "#             if id in mincedResults:\n",
    "#                 mincedResults[id].combineResults(locus)\n",
    "    elif not noMinced:\n",
    "        crisprs_only_in_minced += 1\n",
    "        minCED_results[protID]  = MinCEDReader(mincedFileName)\n",
    "        minCED_results[protID].calulate_consensus_seqs()\n",
    "    elif not noPiler:\n",
    "        crisprs_only_in_piler += 1\n",
    "        pilerCR_results[protID] = PilerCRReader(pilerCRFileName)\n",
    "    else:\n",
    "        no_results += 1\n",
    "        noCRISPR.add(protID)\n",
    "        #Remove files to ensure integrity of data\n",
    "        #os.system(\"rm -f %s %s\" % (mincedFileName, pilerCRFileName ))  #TODO Delete this after have run once\n",
    "\n",
    "crisprsFound = crisprs_in_both + crisprs_only_in_minced + crisprs_only_in_piler\n",
    "print \"Found %i crisprs in %s assemblies\" % (crisprsFound,crisprsFound+no_results)\n",
    "print \"\\tBoth:\", crisprs_in_both\n",
    "print \"\\tMinced only:\", crisprs_only_in_minced\n",
    "print \"\\tPiler only:\", crisprs_only_in_piler\n",
    "#print \"\\tNo CRISPR:\",no_results, len(noCRISPR)\n",
    "pickle.dump(minCED_results,open(\"pickles/MinCED_CRISPRS.p\",\"wb\"))\n",
    "pickle.dump(pilerCR_results,open(\"pickles/PilerCR_CRISPRS.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minCED_results, pilerCR_results = {},{}\n",
    "crisprs_in_both, crisprs_only_in_piler, crisprs_only_in_minced, no_results, counter = 0, 0, 0, 0, 0\n",
    "crisprResultFiles = glob(\"crisprs/*.pcrout\")\n",
    "noCRISPR = set()\n",
    "\n",
    "for pilerCRFileName in crisprResultFiles:\n",
    "    protID = pilerCRFileName.replace(\".pcrout\",\"\").replace(\"crisprs/\",\"\")\n",
    "    if protID not in casRelatedAssemblies: continue\n",
    "    mincedFileName = pilerCRFileName.replace(\"pcrout\",\"mnout\")\n",
    "    noMinced = (stat(mincedFileName).st_size == 0)\n",
    "    noPiler = (stat(pilerCRFileName).st_size <= 200)\n",
    "    \n",
    "    if not noMinced and not noPiler:\n",
    "        crisprs_in_both +=1\n",
    "        minCED_results[protID]  = MinCEDReader(mincedFileName)\n",
    "        pilerCR_results[protID] = PilerCRReader(pilerCRFileName)\n",
    "        minCED_results[protID].calulate_consensus_seqs()\n",
    "#         for id,locus in pilercrResults.iteritems():\n",
    "#             if id in mincedResults:\n",
    "#                 mincedResults[id].combineResults(locus)\n",
    "    elif not noMinced:\n",
    "        crisprs_only_in_minced += 1\n",
    "        minCED_results[protID]  = MinCEDReader(mincedFileName)\n",
    "        minCED_results[protID].calulate_consensus_seqs()\n",
    "    elif not noPiler:\n",
    "        crisprs_only_in_piler += 1\n",
    "        pilerCR_results[protID] = PilerCRReader(pilerCRFileName)\n",
    "    else:\n",
    "        no_results += 1\n",
    "        noCRISPR.add(protID)\n",
    "        #Remove files to ensure integrity of data\n",
    "        #os.system(\"rm -f %s %s\" % (mincedFileName, pilerCRFileName ))  #TODO Delete this after have run once\n",
    "\n",
    "crisprsFound = crisprs_in_both + crisprs_only_in_minced + crisprs_only_in_piler\n",
    "print \"Found %i crisprs in %s assemblies\" % (crisprsFound,crisprsFound+no_results)\n",
    "print \"\\tBoth:\", crisprs_in_both\n",
    "print \"\\tMinced only:\", crisprs_only_in_minced\n",
    "print \"\\tPiler only:\", crisprs_only_in_piler\n",
    "#print \"\\tNo CRISPR:\",no_results, len(noCRISPR)\n",
    "pickle.dump(minCED_results,open(\"pickles/MinCED_CRISPRS.p\",\"wb\"))\n",
    "pickle.dump(pilerCR_results,open(\"pickles/PilerCR_CRISPRS.p\",\"wb\"))\n",
    "#pickle.dump(noCRISPR,open(\"pickles/noCRISPRS.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CRISPRtools import *\n",
    "minCED_results  = pickle.load(open(\"pickles/MinCED_CRISPRS.p\",\"rb\"))\n",
    "pilerCR_results = pickle.load(open(\"pickles/PilerCR_CRISPRS.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickTop(idSet,clustPercs):\n",
    "    if len(idSet) == 1: return list(idSet)[0]\n",
    "    maxID, maxAA = 0, 0\n",
    "    for id in idSet:\n",
    "        if clustPercs[id][0] > maxAA:\n",
    "            maxAA = clustPercs[id][0]\n",
    "            maxID = id\n",
    "    return maxID\n",
    "# hmm_parser = load(open(\"pickles/%s_HMM_Parsing_Results.p\" % (gene),\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crRNALens, crisprLocations, noPredictedTracr, seqLenDist = [],[],[],[]\n",
    "hasNRegionSet,crRNALens, possibleSolutions, newSolutions, index, counter = set(),[], set(), {}, 0, 0\n",
    "allLoci = {}\n",
    "nCounter, n_and_no_possibles = 0,0\n",
    "# novelLoci = pickle.load(open(\"pickles/NovelTracrs.p\",\"rb\"))\n",
    "for protID in casRelatedAssemblies:\n",
    "#     if protID not in novelLoci: continue\n",
    "    #Step 1: Select the CRISPR array from the CRISPR Arrays\n",
    "#     baseID = protID[:protID.find(\"_ORF\")]\n",
    "    if protID not in pilerCR_results and protID not in minCED_results: \n",
    "        die\n",
    "        continue #Missing from both\n",
    "    try: \n",
    "        if protID in pilerCR_results: assemblyLoci = pilerCR_results[protID].values()\n",
    "        else: assemblyLoci = pilerCR_results[baseID].values() #Looking only at the most abundant crispr\n",
    "        for locus in assemblyLoci:\n",
    "            if locus.name == protID: break\n",
    "        if locus.name != baseID: die\n",
    "    except: \n",
    "        try: assemblyLoci = minCED_results[baseID].values()\n",
    "        except: assemblyLoci = minCED_results[protID].values()\n",
    "                 \n",
    "        for locus in assemblyLoci:\n",
    "            if locus.name == baseID: break\n",
    "        if locus.name != baseID: die\n",
    "\n",
    "    write([SeqRecord(id=protID,description='',seq=Seq(locus.consensusRepeat[0]))],\"tmp/consFasta.fa\",\"fasta\")\n",
    "    blast_results = parseSingleBLAST(BLAST_short(\"tmp/consFasta.fa\", \"assemblies/%s.fa\" % (protID), \"tmp/consBlast.xml\"))\n",
    "    \n",
    "    #Step 2b\n",
    "    boundaryHits,crRNALen = locus.checkArrayBoundaries(blast_results)\n",
    "    crRNALens.append(crRNALen)\n",
    "    locus.annotate(casRelatedAssemblies[protID], \"assemblies/%s.fa\" % (protID))\n",
    "    if locus.hasNRegion: \n",
    "        nCounter += 1\n",
    "        hasNRegionSet.add(protID)\n",
    "    allLoci[protID] = locus\n",
    "    \n",
    "    #Step 2c\n",
    "    tmpFasta = open(\"tmp/possibleTracrs.fasta\",\"w\")\n",
    "    \n",
    "    #Step 2d\n",
    "    terminusSeqs, index = locus.getTerminusRepeats(casRelatedAssemblies[protID],index)\n",
    "    tmpFasta.write(terminusSeqs)\n",
    "    \n",
    "    #Collect some stats\n",
    "    startCoord = locus.repeatCoords[0]\n",
    "    endCoord = locus.repeatCoords[-1]\n",
    "    seqlen = len(casRelatedAssemblies[protID])\n",
    "    seqLenDist.append(seqlen)\n",
    "    minDist = min(seqlen-startCoord.start,seqlen-startCoord.end,seqlen-endCoord.start,seqlen-endCoord.end)\n",
    "    minDist =  min(minDist,startCoord.start,startCoord.end,endCoord.start,endCoord.end)\n",
    "    crisprLocations.append(minDist)\n",
    "\n",
    "    ##Step 2e - Write sequence surounding hits to the fasta file\n",
    "    for rec in boundaryHits: index = getSurroundingSequence(tmpFasta,index,casRelatedAssemblies[protID],rec,500)\n",
    "    \n",
    "    ##Step 2f - Look for terminators in the possible tracrRNAs\n",
    "    tmpFasta.close()\n",
    "    cmd = \"~/bin/Arnold/erpin ~/bin/Arnold/rho-indep.epn tmp/possibleTracrs.fasta -1,4 -add 1 4 2 -pcw 1 -cutoff 100% >tmp/rhoInd.out\"\n",
    "    system(cmd)\n",
    "    \n",
    "    ##Setp 2j - process the terminators that were found\n",
    "    erpOut = ErpinOut()\n",
    "    if len(erpOut.terminators)==0: \n",
    "        print \"\\nThis ref has nothing: %s\\n\" % protID\n",
    "        noPredictedTracr.append(protID)\n",
    "        if locus.hasNRegion: n_and_no_possibles +=1\n",
    "    else: \n",
    "        newSolutions[protID] = erpOut\n",
    "        repeatIndex = 0\n",
    "    \n",
    "    ## Everything below this point is for getting and annotation a genbank file for the assembly associated with the CRISPR ##\n",
    "    ##Look through terminators\n",
    "    for terminator in erpOut.terminators:\n",
    "        info= terminator.name.split(\"_\")\n",
    "        whereRepeat = (info[1] == \"S\")\n",
    "        start = int(info[-3])\n",
    "        end = int(info[-2])\n",
    "        strand = -1\n",
    "        if terminator.strand == \"+\": strand = 1\n",
    "        if whereRepeat: \n",
    "            tracr_size = end - (end-min(terminator.Rholocation.start, terminator.Rholocation.end))\n",
    "            if tracr_size > 350:continue\n",
    "            repeatFeature = SeqFeature(FeatureLocation(end-min(terminator.Rholocation.start, terminator.Rholocation.end), end), type=\"CDS\", strand=strand)\n",
    "        else: \n",
    "            tracr_size = (start + max(terminator.Rholocation.start, terminator.Rholocation.end)) - start\n",
    "            if tracr_size > 350:continue\n",
    "            repeatFeature = SeqFeature(FeatureLocation(start,start + max(terminator.Rholocation.start, terminator.Rholocation.end)), type=\"CDS\", strand=strand)\n",
    "        fid = \"Theoretical tracrRNA_%i\" % (repeatIndex)\n",
    "        repeatFeature.qualifiers['label'] = [fid]\n",
    "#         locus.orfs.records[baseID].features.append(repeatFeature)\n",
    "        repeatIndex += 1 \n",
    "    \n",
    "    #shift annoations by buffer\n",
    "# #     if not locus.orfs:continue\n",
    "#     locus.orfs.records[baseID].seq = locus.orfs.records[baseID].seq[max(locus.min-500,0):locus.max+500]\n",
    "#     #locus.orfs.records[protID].seq = locus.orfs.records[protID].seq[max(locus.min-500,0):locus.max+500]\n",
    "#     for rec in locus.orfs.records[baseID].features:\n",
    "# #         print \"This is the start:\", rec.location.start - max(locus.min-100,0), rec.location.end - max(locus.min-100,0),rec.location.start,rec.location.end\n",
    "#         rec.location = FeatureLocation(rec.location.start - max(locus.min-500,0), rec.location.end - max(locus.min-500,0))\n",
    "# #         print \"This is the   end:\", rec.location.start, rec.location.end\n",
    "    \n",
    "    # Step 2k Create setup for GB file for Vector NTI\n",
    "#     for id in locus.orfs.records:\n",
    "#         print \"annotations/%s.gb\" % (locus.name)\n",
    "#         fh = open(\"annotations/%s.gb\" % (locus.name),\"w\")\n",
    "#         biopythonID = id[:id.find(\":\")-1] #Biopython limits genbank file ids to 16 characters\n",
    "#         locus.orfs.records[id].id = biopythonID[:16]\n",
    "#         locus.orfs.records[id].name = biopythonID[:16]\n",
    "#         write([locus.orfs.records[id]],fh,'genbank')\n",
    "#         fh.close()\n",
    "print (len(allLoci))\n",
    "pickle.dump(allLoci,open(\"pickles/TracrLoci.p\",\"wb\"))    \n",
    "pickle.dump(newSolutions,open(\"pickles/%s_predictedTracrRNAs.p\" % (gene),\"wb\"))\n",
    "print(\"\\n\\nNumber of proteins with large N region and no terminator / with total large N region: %i / %i\" % (n_and_no_possibles,nCounter))\n",
    "print(\"%i possible solutions in %s references. Nothing found in %i references\" % (index-1, len(newSolutions),len(noPredictedTracr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilerCR_results, multipleCRISPRS = {}, {}\n",
    "badIDs,numRepeats,geneIDs = [],[],[]\n",
    "# crisprResultFiles = glob(\"crisprs/*.pcrout\")\n",
    "for protID in casRelatedAssemblies:\n",
    "    crisprResults = PilerCRReader(\"crisprs/%s.pcrout\" % (protID))\n",
    "    baseChrID = protID[:protID.rfind(\"_\")]\n",
    "    if len(crisprResults) > 1: multipleCRISPRS[protID] = crisprResults\n",
    "    try: pilerCR_results[protID] = crisprResults[baseChrID]\n",
    "    except: badIDs.append(protID); continue\n",
    "    numRepeats.append(len(pilerCR_results[protID].repeatCoords))\n",
    "    geneIDs.append(protID)\n",
    "dump(pilerCR_results,\"pickles/%s_pilerCR_results.p\" % (gene))\n",
    "print(len(casRelatedAssemblies)-len(badIDs))\n",
    "badIDs = set(badIDs)\n",
    "dump(badIDs,\"pickles/badIDs.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPos, numTerminators, tracrSeqDict = {}, {}, {}\n",
    "newSolutions = pickle.load(open(\"pickles/%s_predictedTracrRNAs.p\" % (gene),\"rb\"))\n",
    "index = 0\n",
    "sizeDist = []\n",
    "ignoreSol = 0\n",
    "possibleSol = open(\"sequences/%s_predictedTracrRNAs.fasta\" % (gene),\"w\")\n",
    "for ref,psol in newSolutions.iteritems():\n",
    "    if ref not in casRelatedAssemblies_NoTracr:continue\n",
    "    for terminator in psol.terminators:\n",
    "        seq = psol.records[terminator.name]\n",
    "        solSize = 0\n",
    "        if terminator.fwd: \n",
    "            solSize = terminator.Rholocation.end\n",
    "            tracrSeq = seq[:solSize].upper()\n",
    "        else: \n",
    "            solSize = len(seq) - terminator.Rholocation.start-1\n",
    "            tracrSeq = seq[terminator.Rholocation.start-1:].upper()\n",
    "        sizeDist.append(solSize)\n",
    "        if solSize>350 or tracrSeq.count(\"N\")>=4:\n",
    "            ignoreSol+=1\n",
    "            continue\n",
    "        index += 1\n",
    "        tracrSeqDict[\"%s_%i\" % (ref,index)] = tracrSeq\n",
    "        possibleSol.write(\">%s_%i\\n%s\\n\" % (ref,index,tracrSeq))\n",
    "\n",
    "possibleSol.close()\n",
    "print \"Ignored %i solutions\" % ignoreSol\n",
    "print \"Done\", index, \"possible solutions\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from matplotlib import pyplot as plt\n",
    "ser = Series(sizeDist)\n",
    "plt.hist(ser,bins=20, color='c')\n",
    "plt.axvline(350, color='b', linestyle='dashed', linewidth=2)\n",
    "plt.text(95,800,'tracrRNA Length cuttoff  ->')\n",
    "plt.show()\n",
    "print ser.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = ser[ser<350]\n",
    "plt.hist(ser,bins=20, color='c')\n",
    "plt.title = \"Possible tracrRNA length distribution\"\n",
    "plt.show()\n",
    "print ser.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = Series(crRNALens)\n",
    "ser = ser [ser > 40]\n",
    "ax = ser.plot.hist(bins=20,title=\"Test\",normed=True,color='g',edgecolor=\"k\") #,grid=True)\n",
    "ax.set_xlabel(\"Number of base pairs in average crRNA in CRISPR\")\n",
    "ax.set_ylabel(\"% Frequency\")\n",
    "ax\n",
    "print ser.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd-hit-est -i sequences/PredictedTracrRNAs.fa -o clusters/PredictedTracrRNAs.grouped.fa -M 0 -d 0 -c .90 -T 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterID = \"\"\n",
    "allClusters, allClusterSeqIDs = {},{}\n",
    "# print tracrSeqDict.keys()\n",
    "for line in open(\"clusters/PredictedTracrRNAs.grouped.fa.clstr\"):\n",
    "    if \">Cluster\" in line:\n",
    "        clusterID = line.strip().replace(\">\",\"\")\n",
    "    else:\n",
    "        sequenceID = line[line.find(\">\")+1:line.find(\".\")] \n",
    "        seqID = line[line.find(\">\")+1:line.find(\"...\")] \n",
    "        seqID = seqID[:seqID.rfind(\"_\")]\n",
    "        try:allClusters[clusterID].add(seqID)\n",
    "        except:allClusters[clusterID]=set([seqID])\n",
    "        try:allClusterSeqIDs[seqID].add(clusterID)\n",
    "        except:allClusterSeqIDs[seqID]=set([clusterID])\n",
    "\n",
    "\n",
    "xs,ys,zs=[],[],[]\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#for i in range(2,50):\n",
    "remove=set()\n",
    "colors,TreeColors={},{}\n",
    "clusterDist=[]\n",
    "for cluster, ids in allClusters.iteritems():\n",
    "    clusterDist.append(len(ids))\n",
    "    if len(ids) < 2: remove.add(cluster)\n",
    "    else:\n",
    "        colors[cluster]=color()\n",
    "        for id in ids:TreeColors[id.replace(\".\",\"_\")] = colors[cluster]\n",
    "for id in remove: del allClusters[id]\n",
    "\n",
    "print \"\\tTotal number of clusters:\",len(allClusters)\n",
    "print \"\\tNumber of nodes covered:\",len(TreeColors)\n",
    "\n",
    "# xs.append(len(allClusters))\n",
    "# ys.append(len(TreeColors))\n",
    "# zs.append(i)\n",
    "# ax.scatter(ys,xs,zs)    \n",
    "# # xs.reverse()\n",
    "# # ys.reverse()\n",
    "# # plt.plot(xs, ys, 'ro')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casRelatedAssemblies = fasta_index(\"proteins/%s-Like-clustered.faa\" % (gene),\"fasta\")\n",
    "casRelatedAssemblies = dict(casRelatedAssemblies)\n",
    "badIDs = load(open(\"pickles/badIDs.p\",\"rb\"))\n",
    "allClusters = load(open(\"pickles/%s_ClusteringResults.p\" % (gene),'rb'))\n",
    "allClusterSeqIDs = load(open(\"pickles/%s_RevClusteringResults.p\" % (gene),'rb'))\n",
    "assembliesWCrisprs = load(open(\"pickles/allAssemblyW_CRISPRs.p\",\"rb\"))\n",
    "pilerCR_results = load(open(\"pickles/%s_pilerCR_results.p\" % (gene),\"rb\"))\n",
    "protAssemblyMap = load(open(\"pickles/%s_protAssemblyMap.p\" % gene,\"rb\"))\n",
    "clusterPercs = load(open(\"pickles/%s_ClusterPercs.p\" % (gene),\"rb\"))\n",
    "crPath = \"/mnt/research/germs/shane/databases/crisprs/pilerCR\"\n",
    "eq = 0\n",
    "progress = True \n",
    "badCounter = len(badIDs) \n",
    "rounds = 0 \n",
    "while badCounter != 0 and progress:\n",
    "    lastLen = badCounter\n",
    "    rounds += 1\n",
    "    replaced,failed = set(),set()\n",
    "    print(\"Round %i - %i\" % (rounds,len(badIDs)))\n",
    "    for badID in badIDs:\n",
    "        idCluster = list(allClusterSeqIDs[badID])[0]\n",
    "        replacementIDS = allClusters[idCluster]\n",
    "        if badID in replacementIDS: replacementIDS.remove(badID)\n",
    "        if len(replacementIDS) > 0 :\n",
    "            eqID = pickTop(replacementIDS,clusterPercs)\n",
    "            del clusterPercs[eqID]\n",
    "            badCounter -= 1\n",
    "            replaced.add(badID)\n",
    "            crisprResults = PilerCRReader(\"crisprs/%s.pcrout\" % (eqID))\n",
    "            baseProtID = eqID[:eqID.rfind(\"_\")]\n",
    "            try: \n",
    "                pilerCR_results[eqID] = crisprResults[baseProtID]\n",
    "                if (len(crisprResults) > 1): multipleCRISPRS[eqID] = crisprResults\n",
    "                asmID = protAssemblyMap[eqID]\n",
    "                asmbly = fasta_index(assembliesWCrisprs[asmID],\"fasta\")\n",
    "                asmbly[baseProtID].id = eqID\n",
    "                casRelatedAssemblies[eqID] = asmbly[baseProtID]\n",
    "                del casRelatedAssemblies[badID]\n",
    "                eq += 1\n",
    "            except: failed.add(eqID)\n",
    "    badIDs = badIDs.difference(replaced)\n",
    "    badIDs = badIDs.union(failed)\n",
    "    progress = (lastLen != badCounter)\n",
    "dump(pilerCR_results,\"pickles/%s_pilerCR_results.p\" % (gene))\n",
    "len(badIDs), len(casRelatedAssemblies), eq, rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterDist = Series(clusterDist)\n",
    "clusterDist.plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist=[]\n",
    "for cluster, ids in allClusterSeqIDs.iteritems():\n",
    "    id_len = len(ids)\n",
    "    if id_len > 3: dist.append(id_len)\n",
    "dist = Series(dist)\n",
    "dist.plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpDict = {}\n",
    "tracrSeqDict = fasta_index(\"sequences/PredictedTracrRNAs.fa\",\"fasta\")\n",
    "for id,seq in tracrSeqDict.iteritems(): tmpDict[id[:id.rfind(\"_\")]]=str(seq.seq).upper()\n",
    "tracrSeqDict = tmpDict  \n",
    "for cluster, seqIDList in allClusters.iteritems():\n",
    "    clusterFileName = \"conseqs1/\"+cluster.replace(\" \",\"_\")+\".fasta\"\n",
    "    fh = open(clusterFileName,\"wb\")\n",
    "    clusterStats = []\n",
    "    for seqID in seqIDList: clusterStats.append(len(tracrSeqDict[seqID]))\n",
    "    clusterStats = Series(clusterStats)\n",
    "    keepSeqs = clusterStats[~((clusterStats-clusterStats.mean()).abs() > clusterStats.std())]\n",
    "    minSeq, maxSeq = keepSeqs.min(), keepSeqs.max()\n",
    "    index=0\n",
    "    for seqID in seqIDList: \n",
    "        seqLen = len(tracrSeqDict[seqID])\n",
    "        if seqLen >= minSeq and seqLen <= maxSeq:\n",
    "            index+=1\n",
    "            fh.write(\">%s\\n%s\\n\" % (seqID,tracrSeqDict[seqID]))\n",
    "    fh.close()\n",
    "    if index <= 1:\n",
    "        os.system(\"rm %s\" % (clusterFileName))\n",
    "        continue\n",
    "    print clusterFileName,\"(\",index,\"/\",len(seqIDList), \")[%i,%i]\" % (minSeq,maxSeq),clusterStats.std() \n",
    "    os.system(\"cd-hit-est -i %s -o %s_cluster -M 0 -d 0 -c .90 -T 0 -sc 1\" % (clusterFileName,clusterFileName))\n",
    "    clusteredResults = processClusterFile(\"%s_cluster.clstr\" % (clusterFileName))\n",
    "    fh = open(clusterFileName,\"wb\")\n",
    "    index = 0 \n",
    "    for seqID,direction in clusteredResults.filter():\n",
    "        index +=1\n",
    "        if direction: fh.write(\">%s\\n%s\\n\" % (seqID,str(tracrSeqDict[seqID])))\n",
    "        else: fh.write(\">%s\\n%s\\n\" % (seqID, reverse_complement(tracrSeqDict[seqID])))\n",
    "    fh.close()\n",
    "    if index <= 1:\n",
    "        os.system(\"rm %s\" % (clusterFileName))\n",
    "    os.system(\"rm %s_cluster*\" % (clusterFileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in 1 2 3 4 5 6 7 8 9 10\n",
    "do\n",
    "    sbatch ../scripts/StructureSearch.sb\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the infernal results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infernalResults = ProcessInfernal(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a structural results tree uisng a combination of the previous and current search results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Build color mappers and counters and separate into groups</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knownTracrRNAs = load(open(\"pickles/KnownTracrStuctureHitColors.p\",\"rb\"))\n",
    "knownTracrIDColorMap, knownTracrColorCounter = {}, {}\n",
    "for id,color in knownTracrRNAs.iteritems():\n",
    "    try:knownTracrIDColorMap[color].add(id)\n",
    "    except:knownTracrIDColorMap[color]=set([id])\n",
    "    try:knownTracrColorCounter[color]+=1\n",
    "    except:knownTracrColorCounter[color]=1\n",
    "knownTracrColorCounter = Counter(knownTracrColorCounter)\n",
    "unknownClusterCounter = {}\n",
    "for struct,ids in infernalResults.structMapping.iteritems(): unknownClusterCounter[struct] = len(ids)\n",
    "\n",
    "#Tell us about what we are annotating\n",
    "unknownTracrRNAs = set(casRelatedAssemblies.keys()).difference(knownTracrRNAs)        \n",
    "print \"Known:%i/%i\\nUnknown:%i/%i\\n\\tClusters:%i\\n\" % (len(knownTracrRNAs),len(casRelatedAssemblies),len(unknownTracrRNAs),len(casRelatedAssemblies),len(knownTracrColorCounter)) \n",
    "\n",
    "newTracrRNAs = set(unknownTracrRNAs).intersection(infernalResults)\n",
    "allFound = set(knownTracrRNAs.keys()).union(infernalResults)\n",
    "stillMissing = set(casRelatedAssemblies.keys()).difference(allFound)\n",
    "print \"Found: %i/%i\\nRemaining: (%i/%i or %i/%i)\\n\\tClusters: %i\" % (len(newTracrRNAs),len(unknownTracrRNAs),len(stillMissing),len(unknownTracrRNAs),len(stillMissing),len(casRelatedAssemblies),len(unknownClusterCounter))\n",
    "\n",
    "print \"TracrRNAs:\\n\\t%i/%i Found\\n\\tClusters %i  or less because predicted may not have been picked up in previous search\" % (len(knownTracrRNAs)+len(newTracrRNAs),len(casRelatedAssemblies),len(unknownClusterCounter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Divide the groups into their new/shared colors</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBiggestCluster(clusters, clusterMap): return Counter(dict((k, clusterMap[k]) for k in (clusters))).most_common(1)[0][0] \n",
    "\n",
    "newColors,newColorMap, TreeColors,newIDs = {}, {}, knownTracrRNAs.copy(), set()\n",
    "startLen = len(TreeColors)\n",
    "print \"Started with %i tracrRNAs\" % (startLen)\n",
    "for seqID in newTracrRNAs:\n",
    "#     print \"Next\",seqID\n",
    "    #Get all the clusters the ID is associated with:\n",
    "    clusters = infernalResults[seqID]\n",
    "    \n",
    "    #Get all of the IDs associated with those clusters\n",
    "    clusterIDS = set()\n",
    "    for cluster in clusters: clusterIDS = clusterIDS.union(infernalResults[cluster])\n",
    "        \n",
    "    #Check to see if there is overlap betweeb the IDs of the known and the IDs of the predicted for this new tracr\n",
    "    overlappingIDs = clusterIDS.intersection(knownTracrRNAs)\n",
    "    \n",
    "    if len(overlappingIDs)>0:#If there is overlap\n",
    "        #Get the cluster color(s) of the overlapping IDs\n",
    "        colors = set()\n",
    "        for o_id in overlappingIDs: colors.add(knownTracrRNAs[o_id])\n",
    "            \n",
    "        #Choose the biggest color\n",
    "        id_color = findBiggestCluster(colors,knownTracrColorCounter)\n",
    "\n",
    "    else: #No overlap, choose the best color from new clusters\n",
    "        biggestCluster = findBiggestCluster(clusters,unknownClusterCounter)\n",
    "        try: id_color = newColors[biggestCluster]; newColorMap[newColors[biggestCluster]].add(seqID)\n",
    "        except: id_color = newColors[biggestCluster] = genColor(); newColorMap[newColors[biggestCluster]] = set([seqID])\n",
    "        newIDs.add(seqID)\n",
    "    TreeColors[seqID] = id_color\n",
    "\n",
    "print \"Annotated %i/%i\" % (len(TreeColors),len(casRelatedAssemblies))\n",
    "print \"\\t\",len(TreeColors)-startLen, \"found\"\n",
    "print \"\\t\",len(newIDs), \"/\", len(TreeColors)-startLen, \"contain a unique structure\"\n",
    "print \"\\t\",len(newColors), \"/\", len(newColors)+len(knownTracrColorCounter), \"new clusters\"\n",
    "\n",
    "dump(TreeColors, \"pickles/PredictedTracrRNA_colors.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats on what was found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = []\n",
    "for ids in newColorMap.values(): dist.append(len(ids))\n",
    "dist = Series(dist)\n",
    "#print dist.describe()\n",
    "dist.plot.hist();  \n",
    "print \"Total of %i novel tracrRNA clusters\" % (len(newColorMap))\n",
    "print \"Containing %i tracrRNAs\" % (dist.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visually inspect what results are new and especially those in new clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TreeColors = pickle.load(open(\"pickles/PaperCombinedTreeColors.p\"))\n",
    "knownBoth, structOnly, blastOnly= set(),set(),set()\n",
    "for id,color in TreeColors.iteritems():\n",
    "    if   color == \"#70857A\": knownBoth.add(id)\n",
    "    elif color == \"#F4B266\": structOnly.add(id)\n",
    "    elif color == \"#9B7E46\": blastOnly.add(id)\n",
    "print len(knownBoth), len(structOnly), len(blastOnly),\"\\n\"\n",
    "\n",
    "print len(knownBoth.intersection(newIDs))\n",
    "print len(structOnly.intersection(newIDs))\n",
    "print len(blastOnly.intersection(newIDs)), \"That's interesting\"\n",
    "\n",
    "for id in newTracrRNAs: TreeColors[id] = \"#0099ff\"\n",
    "dump(TreeColors,\"pickles/PredictedTracrRNA_colors_bySearchMethod.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Artifacts Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_s = open(\"proteins/%s-Like-clustered_full.faa\" % (gene),\"w\")\n",
    "fasta = open(\"assemblies/%s_Representative_Assemblies.fasta\" % (gene),\"w\")\n",
    "for id,rec in casRelatedAssemblies.items():\n",
    "    write(rec,aa_s,\"fasta\")\n",
    "    protAsm = fasta_index(\"assemblies/pseudoChromos/%s.fasta\" % (id), \"fasta\")\n",
    "    write(protAsm[id],fasta,\"fasta\")\n",
    "fasta.close()\n",
    "aa_s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "for cluster, ids in allClusters.iteritems():\n",
    "    if len(ids)<=3:continue\n",
    "    maxOverlap = 0\n",
    "    for seq1, seq2 in itertools.combinations(ids, 2):\n",
    "        maxOverlap = max(len(allClusterSeqIDs[seq1].intersection(allClusterSeqIDs[seq2])),maxOverlap)\n",
    "    print cluster, \"%i/%i\" % (maxOverlap, len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, ids in allClusterSeqIDs.iteritems():\n",
    "    print cluster\n",
    "    num=0\n",
    "    for id in ids:\n",
    "        num+=1\n",
    "        print \"\\t%i. %s\" % (num,id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqIO import parse, write\n",
    "casRelatedAssemblies = {}\n",
    "for id in allCas9s:\n",
    "    seqID = id[:id.rfind(\"_\")]\n",
    "    for rec in parse(\"assemblies/%s.fasta\" % id,\"fasta\"):\n",
    "        if rec.id == seqID:\n",
    "#             with open(\"assemblies/%s.fa\" % id, \"wb\") as fh:\n",
    "#                 write([rec],fh,\"fasta\") \n",
    "            casRelatedAssemblies[id]=str(rec.seq)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(\"casRelatedAssemblies.fasta\",\"wb\")\n",
    "for id,seq in casRelatedAssemblies.iteritems(): fh.write(\">%s\\n%s\\n\" % (id,seq))\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPos\n",
    "numTerminators\n",
    "tracrSeqDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newSolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir tmp\n",
    "ls -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### ARTIFACTS BELOW ###########################\n",
    "clusterSizes = []\n",
    "index = 0\n",
    "colors = {\n",
    "    0:\"#C0C0C0\", 1:\"#808080\",\n",
    "    2:\"#FF0000\", 3:\"#800000\",\n",
    "    4:\"#FFFF00\", 5:\"#808000\",\n",
    "    6:\"#00FF00\", 7:\"#008000\",\n",
    "    8:\"#00FFFF\", 9:\"#008080\",\n",
    "    10:\"#0000FF\", 11:\"#000080\",\n",
    "    12:\"#FF00FF\", 13:\"#800080\",\n",
    "    14:\"#DAF7A6\", 15:\"#FF5733\",\n",
    "    16:\"#C70039\", 17:\"#900C3F\",\n",
    "    18:\"#900C3F\", 19:\"#900C3F\",\n",
    "    20:\"#900C3F\", 21:\"#900C3F\",\n",
    "    22:\"#900C3F\", 23:\"#900C3F\",\n",
    "    24:\"#900C3F\", 25:\"#900C3F\",\n",
    "    26:\"#900C3F\", 27:\"#900C3F\"\n",
    "}\n",
    "# for cluster in allClusters: \n",
    "#     clusterSizes.append(len(allClusterSeqIDs[cluster]))\n",
    "#     if len(allClusterSeqIDs[cluster])>=3: \n",
    "#         fh = open(\"data/%s.fa\" %(cluster.replace(\" \",\"_\")),\"w\")\n",
    "#         for id in allClusters[cluster]: \n",
    "#             fh.write(\">%s\\n%s\\n\" % (id,tracrSeqDict[id]))\n",
    "#             #TreeColors[id[:id.find(\"_\")]] = colors[index]\n",
    "#             print id[:id.find(\"_\")],\n",
    "#         print\n",
    "#         index += 1\n",
    "#         fh.close()\n",
    "#     print \"data/%s.fa\" % (cluster.replace(\" \",\"_\"))\n",
    "# print \"# indices needed:\", index-1\n",
    "# ser = Series(clusterSizes)\n",
    "# ser.plot.hist()\n",
    "# print ser.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"./\")\n",
    "for fn in files:\n",
    "    baseid = fn[:fn.find(\"_ORF\")]+\"_orfs.blastout\"\n",
    "    #os.system(\"mv %s %s\" % (fn,baseid))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.pairwise2 import align\n",
    "from Bio.pairwise2 import format_alignment\n",
    "crRNA = RC(\"GTTGTGATTTGCTTTAA\")\n",
    "tracrRNA = \"TTAAAGCAATTCACAATAAGGATTATTCCGATGTGAAAACATTAGGTTGCCTCGTCCTACCATACGGGGCTTTTTTT\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# bestAln = None\n",
    "# bestMatch, bestGap = 0,0\n",
    "# bestScore = 0\n",
    "# for matchScore in np.arange(0.1, 3.0, 0.1):\n",
    "#     for gapPenalty in np.arange(0.1, 15.0, 0.1):\n",
    "#         alignment = align.globalmx(tracrRNA, crRNA,matchScore,-gapPenalty)[0]\n",
    "#         if alignment[2] > bestScore:\n",
    "#             bestScore = alignment[2]\n",
    "#             bestMatch = matchScore\n",
    "#             bestGap = gapPenalty\n",
    "#             bestAln = alignment\n",
    "\n",
    "# print (bestScore,bestGap,bestMatch)\n",
    "# print(format_alignment(*bestAln))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracrRNA)\n",
    "print(crRNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crRNA[-1], tracrRNA[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Align\n",
    "from Bio.SubsMat import MatrixInfo\n",
    "\n",
    "aligner = Align.PairwiseAligner()\n",
    "# aligner.substitution_matrix = MatrixInfo.blosum30\n",
    "# aligner.mode = 'local'\n",
    "\n",
    "bestAln = None\n",
    "bestMatch, bestGap = 0,0\n",
    "bestOpen, bestExtend= 0,0\n",
    "bestScore = 0\n",
    "for matchScore in np.arange(0.5, 10.0, 0.5):\n",
    "    for mismatchScore in np.arange(0.0, 10.0, 0.5):\n",
    "        for openPenalty in np.arange(0.1, 10.0, 0.1):\n",
    "            for extendPenatly in np.arange(0.1, 2.0, 0.1):\n",
    "                aligner.open_gap_score = -openPenalty\n",
    "                aligner.extend_gap_score = -extendPenatly\n",
    "                aligner.match = matchScore\n",
    "                aligner.mismatch = -mismatchScore\n",
    "                alignment = aligner.align(tracrRNA, crRNA)\n",
    "                if alignment.score > bestScore:\n",
    "                    bestScore = alignment.score\n",
    "                    bestMatch = matchScore\n",
    "                    bestGap = -mismatchScore\n",
    "                    bestOpen = -openPenalty\n",
    "                    bestExtend = -extendPenatly\n",
    "                    bestAln = alignment\n",
    "print(\"Score = %.1f:\" % bestScore)       \n",
    "print(bestAln[0])\n",
    "print(bestOpen,bestExtend)\n",
    "print(bestMatch,bestGap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAln[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Custom Functions ################################\n",
    "from Bio.SubsMat import MatrixInfo as matlist\n",
    "matrix = matlist.blosum62\n",
    "gap_open = -8\n",
    "gap_extend = -.8\n",
    "\n",
    "def RC(seq): return str(Seq(seq).reverse_complement())\n",
    "def scoreAlign(alignment):\n",
    "    ref, frag, score, begin, end = alignment\n",
    "    matches = 0\n",
    "    for pos in range(len(ref)):\n",
    "        if ref[pos] == frag[pos]:matches+=1\n",
    "    return matches/float(len(frag.replace(\"-\",\"\")))         \n",
    "def scoreAligns(aln1,aln2):\n",
    "    score1, score2 = scoreAlign(aln1), scoreAlign(aln2)\n",
    "    if score1 > score2: return aln1,score1*100\n",
    "    else: return aln2, score2*100   \n",
    "    \n",
    "def alignSequences(refSeq,fragment):\n",
    "    try: aln1 = pairwise2.align.globalds(refSeq, fragment, matrix, gap_open, gap_extend)[0]\n",
    "    except: aln1 = None\n",
    "    try: aln2 = pairwise2.align.globalds(refSeq, RC(fragment), matrix, gap_open, gap_extend)[0]\n",
    "    except: aln2 = None\n",
    "    if aln1 == None and aln2 == None: return None,0\n",
    "    elif aln1 == None: top_aln = aln2\n",
    "    elif aln2 == None: top_aln = aln1\n",
    "    else: top_aln,alnScore = scoreAligns(aln1,aln2)\n",
    "    if alnScore == None: alnScore = 0    \n",
    "    if top_aln == None:print \"Here\"\n",
    "    aln_probe, aln_arms, score, begin, end = top_aln\n",
    "    return alnScore\n",
    "\n",
    "def alignSequence(refSeq,fragment):\n",
    "    aln1 = pairwise2.align.globalds(refSeq, fragment, matrix, gap_open, gap_extend)[0]\n",
    "    try: aln1 = pairwise2.align.globalds(refSeq, fragment, matrix, gap_open, gap_extend)[0]\n",
    "    except: aln1 = None\n",
    "    try: aln2 = pairwise2.align.globalds(refSeq, RC(fragment), matrix, gap_open, gap_extend)[0]\n",
    "    except: aln2 = None\n",
    "    if aln1 == None and aln2 == None: return None,0\n",
    "    elif aln1 == None: top_aln = aln2\n",
    "    elif aln2 == None: top_aln = aln1\n",
    "    else: top_aln,alnScore = scoreAligns(aln1,aln2)\n",
    "    if alnScore == None: alnScore = 0    \n",
    "    if top_aln == None:print \"Here\"\n",
    "    aln_probe, aln_arms, score, begin, end = top_aln\n",
    "    return '%s\\t%% Matching %.2f%%\\n\\t%s' % (aln_probe, alnScore, aln_arms), alnScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "   \n",
    "#     Temporary method bindings:\n",
    "#     locus.clusterBLASTResults = MethodType(clusterBLASTResults,locus)\n",
    "#     locus.getTracrRNA_Candidates = MethodType(getTracrRNA_Candidates,locus)\n",
    "#     locus.setName = MethodType(setName,locus)\n",
    "#     locus.getAntiRepeatCandidates = MethodType(getAntiRepeatCandidates,locus)\n",
    "#     locus.repeatSeqs = MethodType(repeatSeqs,locus)\n",
    "#     locus.tracrRNACandidateSeqs = set()\n",
    "\n",
    "class AntiRepeatCandidate:\n",
    "    def __init__(self,coord,direction='upstream'):\n",
    "        self.location = coord\n",
    "        self.directions = set([direction])\n",
    "    def addDir(self): self.directions.add('downstream')\n",
    "    def getSeq(self,chrSeq):\n",
    "        retSeqs = []\n",
    "        buffer = 350\n",
    "        seqName = \">Seq_%i_%i_%s\"\n",
    "        for dir in self.directions:\n",
    "            if dir == 'upstream':\n",
    "                start, end = max(self.location.start-buffer,0), self.location.end+1\n",
    "                retSeqs.append(seqName % (start,end,'U'))\n",
    "                retSeqs.append(chrSeq[start:end])\n",
    "            else:\n",
    "                start, end = self.location.start-1, min(self.location.end+buffer,len(chrSeq)-1)\n",
    "                retSeqs.append(seqName % (start,end,'D'))\n",
    "                retSeqs.append(chrSeq[start:end])\n",
    "        return \"\\n\".join(retSeqs)\n",
    "    def __hash__(self): return hash(self.location)\n",
    "    def __str__(self): \n",
    "        dirs = \"upstream/downstream\"\n",
    "        if len(self.directions) == 1: dirs = self.directions.pop()\n",
    "        return str(self.location) + \" \"+dirs\n",
    "    def __lt__(self,other): return self.location < other.location\n",
    "    def __gt__(self,other): return self.location > other.location\n",
    "\n",
    "def clusterBLASTResults(self, blastResults):\n",
    "    spacerLen = len(max(self.spacers, key=len)) + 10\n",
    "    blastResults.sort()\n",
    "#     print(\"Separation:\",spacerLen)\n",
    "    prevResult = blastResults[0]\n",
    "    self.antiRepeats[prevResult] = AntiRepeatCandidate(prevResult)\n",
    "#     print(\"\\t\",prevResult, \"Start\")\n",
    "    for nextResult in blastResults[1:]:\n",
    "        if prevResult.distance(nextResult) > spacerLen: \n",
    "            self.antiRepeats[nextResult] = AntiRepeatCandidate(nextResult)\n",
    "            if prevResult in self.antiRepeats: self.antiRepeats[prevResult].addDir()\n",
    "            else: self.antiRepeats[prevResult] = AntiRepeatCandidate(prevResult,'downstream')\n",
    "#             print(\"\\t\",prevResult,prevResult.distance(nextResult))\n",
    "#         else: print(\"\\t\",nextResult)\n",
    "        prevResult=nextResult\n",
    "    if nextResult in self.antiRepeats: self.antiRepeats[nextResult].addDir()\n",
    "    else:  self.antiRepeats[nextResult] = AntiRepeatCandidate(nextResult,'downstream')\n",
    "#     print(\"Found %i possible candidate anti's\" % (len(self.antiRepeats)))\n",
    "#     resList = list(self.antiRepeats.values())\n",
    "#     resList.sort()\n",
    "#     for res in resList:\n",
    "#         print(\"\\t\",res)\n",
    "#     return nextResult,prevResult\n",
    "def getAntiRepeatCandidates(self,fh,chrSeq):\n",
    "    for antiRepeat in self.antiRepeats.values(): fh.write(antiRepeat.getSeq(chrSeq)+\"\\n\")\n",
    "    fh.close()\n",
    "    \n",
    "def repeatSeqs(self,fh):\n",
    "    for index, repeat in enumerate(self.consensusRepeats): fh.write(\">%s_%i\\n%s\\n\" % (self.name,index,repeat.upper()))\n",
    "    fh.close()\n",
    "def setName(self,name): self.name = name\n",
    "    \n",
    "def getTracrRNA_Candidates(self,erpOut,fh):\n",
    "    if len(erpOut.terminators)==0: \n",
    "        print (\"\\nThis ref has nothing: %s\\n\" % self.name); return\n",
    "    for i,terminator in enumerate(erpOut.terminators):\n",
    "        seq = erpOut.records[terminator.name]\n",
    "        tracrSeq = \"\"\n",
    "        if terminator.upstream and not terminator.strand: tracrSeq = seq[terminator.Rholocation.start-1:].upper()\n",
    "        elif not terminator.upstream and terminator.strand: tracrSeq = seq[:terminator.Rholocation.end].upper()\n",
    "        if tracrSeq.count(\"N\")>=4: continue\n",
    "        if tracrSeq != \"\":\n",
    "            self.tracrRNACandidateSeqs.add(tracrSeq)\n",
    "            fh.write(\">%s_%i\\n%s\\n\" % (self.name,i,tracrSeq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CRISPR predictions to find CRISPR arrays in the genomic assemblies where Cas9s were found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"crisprs\"\n",
    "assembly_dir = \"assemblies/\"\n",
    "assemblies = glob(assembly_dir+\"*.fa\")\n",
    "print \"Number of assemblie to run CRISPR array detection on:\",len(assemblies)\n",
    "for assembly in assemblies:\n",
    "\n",
    "    #Run PilerCR\n",
    "    if path.exists(\"%s/%s.pcrout\" % (outdir, assembly)):retCode1 = 0\n",
    "    else: retCode1 = system(\"pilercr -minid 0.85 -mincons 0.8 -minarray 3 -noinfo -in %s -out %s/%s.pcrout\" %(assembly_dir+assembly, outdir, assembly))\n",
    "        \n",
    "    #Run minced\n",
    "    if path.exists(\"%s/%s.pcrout\" % (outdir, assembly)):retCode2 = 32512\n",
    "    else: retCode2 = system(\"minced -maxSL 75 --maxRL 75 -minRL 16 -minSL 20 -searchWL 6 %s %s/%s.mnout\" % (assembly_dir+assembly, outdir, assembly))\n",
    "    \n",
    "    if retCode1 != 0: \n",
    "        print \"%i\\npilercr -minid 0.85 -mincons 0.8 -minarray 3 -noinfo -in %s -out %s/%s.pcrout\" %(retCode1,assembly_dir+assembly, outdir, assembly)\n",
    "        break\n",
    "    if retCode2 != 32512: \n",
    "        print \"%i\\nminced -maxSL 75 --maxRL 75 -minRL 16 -minSL 20 -searchWL 6 %s %s/%s.mnout\" % (retCode2,assembly_dir+assembly, outdir, assembly)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     rho_s = RhoTermPredict(\"tmp/possibleTracrs.fasta\",\"tmp/RhoPredictions\",protOperon.assembly)\n",
    "#     if not rho_s.hasHits: continue\n",
    "\n",
    "    # Step 7. Read the termination signals\n",
    "    erpOut = ErpinOut()\n",
    "    #rhoOut = RhoTermPredictOut()\n",
    "    erpSols += len(erpOut.terminators)\n",
    "#     rhoSols += len(rhoOut.terminators)\n",
    "\n",
    "    # Step 8. Get tracrRNA candidates with rho-ind signals\n",
    "#     operon.crispr.terminators\n",
    "    operon.crispr.terminators =set()\n",
    "    operon.crispr.getTracrRNA_Candidates = MethodType(getTracrRNA_Candidates,operon.crispr)\n",
    "    operon.crispr.getTracrRNA_Candidates(erpOut,possibleSol)\n",
    "    #rhoOut.terminators = compareTerms(erpOut,rhoOut)\n",
    "    numNewTracrs = len(operon.crispr.tracrRNACandidateSeqs)\n",
    "    if numNewTracrs == 0: noPredictedTracr.add(protID)\n",
    "    totalSols += numNewTracrs\n",
    "    if i in breakPoints: print(i,end=' ')\n",
    "\n",
    "possibleSol.close()\n",
    "# print(\"RhoTermPredict Solutions:\",rhoSols)\n",
    "print(\"\\nErpin Solutions:\",erpSols)\n",
    "dump(casOperons, \"pickles/%s_Operons.p\" % gene)\n",
    "dump(noPredictedTracr, \"pickles/%sWithNoPredictedTracr.p\" % (gene))\n",
    "print(\"Found %i possible tracr solutions from %i assmeblies\" % (totalSols,len(casRelatedAssemblies)-len(noPredictedTracr)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
